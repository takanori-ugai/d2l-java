{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 序文\n",
    "\n",
    "ほんの数年前まで、大手企業や新興企業で知的製品やサービスを開発する深層学習研究者の軍団は存在しなかった。(著者を含む)私たち若手研究者がこの分野に入ったとき、機械学習は日々の新聞の見出しを飾るようなものではなかった。親も機械学習が何なのか知らなかったし、なぜ医学や法律より機械学習がいいのかも知らなかった。機械学習は、現実世界での応用範囲が狭い、未来志向の学問分野であった。また、音声認識やコンピュータビジョンなどのアプリケーションは、非常に多くの専門知識を必要とするため、機械学習はその一部であり、全く別の分野とみなされることが多かった。本書で取り上げるディープラーニングの前身であるニューラルネットワークは、当時は時代遅れの道具とみなされていた。\n",
    "\n",
    "この5年間で、ディープラーニングは世界を驚かせ、コンピュータビジョン、自然言語処理、自動音声認識、強化学習、統計モデリングなど、様々な分野で急速な進歩を遂げた。これらの進歩により、かつてないほどの自律性を備えた自動運転車や（一部の企業が信じ込ませているほど自律性は高くない）、日常的なメールの下書きを自動的に作成し、圧迫感のある大量の受信トレイから人々を救う賢い返信システム、かつて数十年先の偉業と考えられていた囲碁などのボードゲームで世界最高の人間を圧倒するソフトウェアエージェントが実現できる。すでに、これらのツールは産業や社会にこれまで以上の影響を及ぼしており、映画の制作や病気の診断方法を変え、天体物理学から生物学に至るまで基礎科学の分野でも役割を拡大している。\n",
    "\n",
    "\n",
    "## About This Book\n",
    "\n",
    "This book represents our attempt to make deep learning approachable,\n",
    "teaching you the *concepts*, the *context*, and the *code*.\n",
    "\n",
    "### One Medium Combining Code, Math, and HTML\n",
    "\n",
    "どのようなコンピュータ技術であっても、その効果を最大限に発揮するためには、十分に理解され、十分に文書化され、成熟し、よくメンテナンスされたツールによってサポートされている必要がある。キーとなる考え方は明確に抽出され、新しい実務者を最新の状態にするのに必要な時間を最小限に抑える必要がある。成熟したライブラリは、一般的なタスクを自動化し、模範となるコードは、実務家が一般的なアプリケーションを自分のニーズに合わせて変更、適用、拡張することを容易にするものであるべきである。動的なWebアプリケーションを例にとってみると、1990年代には、Amazonのような多くの企業がデータベース駆動型のWebアプリケーションを開発し、成功を収めていたが、この10年間で、創造的な起業家を支援するこの技術の可能性は、強力で十分に文書化されたフレームワークの開発により、はるかに大きな程度まで実現されてきた。\n",
    "\n",
    "\n",
    "ディープラーニングの可能性を検証することは、ユニークな課題である。なぜなら、一つのアプリケーションに様々な分野が集まっているからである。\n",
    "ディープラーニングを適用するには、以下を同時に理解する必要がある。\n",
    "(i) 問題を特定の方法で扱う動機。\n",
    "(ii) 与えられたモデリング手法の数学。\n",
    "(iii) データにモデルを適合させるための最適化アルゴリズム。\n",
    "そして、(iv) モデルを効率的に学習させるために必要なエンジニアリングである。\n",
    "数値計算の落とし穴を回避し、利用可能なハードウェアを最大限に活用する。\n",
    "問題を定式化するために必要な批判的思考力、問題を解くための数学、そしてその解決策を実装するためのソフトウェアツールのすべてを一度に教えることは、困難な課題である。\n",
    "本書の目的は、これから実務に携わろうとする人たちがスピードアップできるような統一されたリソースを提供することである。\n",
    "\n",
    "この本のプロジェクトを開始した時点では、(i)最新で、(ii)現代の機械学習の全範囲を実質的な技術的深さでカバーし、(iii)魅力ある教科書に期待される品質の説明とハンズオンチュートリアルに期待されるクリーンな実行可能コードが交互に並んでいる資料はなかった。私たちは、与えられた深層学習フレームワークの使い方（例えば、TensorFlowで行列を使った基本的な数値計算を行う方法）や特定の技術を実装するためのコード例（例えば、LeNet、AlexNet、ResNetsなどのコード断片）が、様々なブログ記事や GitHub リポジトリに散見されることを知った。しかし，これらの例では，特定のアプローチをどのように実装するかに焦点が当てられており，特定のアルゴリズム的な決定がなぜなされるのかについての議論は省かれている．特定のトピックを扱うインタラクティブなリソースも散見されるが，例えばウェブサイト [Distill](http://distill.pub)で公開された魅力的なブログ記事や個人のブログは，深層学習の特定のトピックのみを取り上げ，関連するコードがないことがある．一方、深層学習の背後にある概念の包括的な調査を提供するいくつかの教科書、特に :cite:`Goodfellow.Bengio.Courville.2016` が出版された一方で、これらのリソースは、説明とコードの概念の実現を結びつけておらず、時には読者がそれらをどのように実装するかについて手掛かりを与えていない。さらに、多くのリソースが商業的なコース提供者のペイウォールの向こう側に隠されている。\n",
    "\n",
    "私たちは、(i)誰でも自由に利用でき、(ii)実際に応用機械学習科学者になるための出発点として十分な技術的深さを提供し、(iii)読者に実際の問題解決方法を示す実行可能コードを含み、(iv)私たちとコミュニティ全体が迅速に更新でき、(v) 技術的詳細について対話的に議論したり質問に答えるための[フォーラム](http://discuss.d2l.ai)によって補完できるリソース作りを目指している。\n",
    "\n",
    "これらの目標はしばしば相反するものであった。方程式、定理、引用文はLaTeXで管理し、レイアウトするのが最適である。コードはPythonで記述するのが最適である。そして、ウェブページはHTMLとJavaScriptで記述するのが最適である。さらに、コンテンツは実行可能なコードとして、物理的な書籍として、ダウンロード可能なPDFとして、そしてインターネット上のウェブサイトとしてアクセスできるようにしたいと考えた。現在、これらの要求に完全に対応するツールやワークフローは存在しないため、私たち自身で構築する必要があった。私たちのアプローチは :numref:`sec_how_to_contribute` で詳しく説明されている。私たちは、ソースの共有と編集を可能にするためにGitHubを、コード、方程式、テキストを混ぜるためにJupyter notebooksを、複数の出力を生成するレンダリングエンジンとしてSphinxを、そしてフォーラムとしてDiscourseを採用することにした。私たちのシステムはまだ完璧ではないが、これらの選択は競合する懸念事項の間の良い妥協点を提供している。このような統合されたワークフローを用いて出版された最初の書籍になるのではないかと考えている。\n",
    "\n",
    "\n",
    "### Learning by Doing\n",
    "\n",
    "Many textbooks teach a series of topics, each in exhaustive detail.\n",
    "For example, Chris Bishop's excellent textbook :cite:`Bishop.2006`,\n",
    "teaches each topic so thoroughly, that getting to the chapter\n",
    "on linear regression requires a non-trivial amount of work.\n",
    "While experts love this book precisely for its thoroughness,\n",
    "for beginners, this property limits its usefulness as an introductory text.\n",
    "\n",
    "In this book, we will teach most concepts *just in time*.\n",
    "In other words, you will learn concepts at the very moment\n",
    "that they are needed to accomplish some practical end.\n",
    "While we take some time at the outset to teach\n",
    "fundamental preliminaries, like linear algebra and probability,\n",
    "we want you to taste the satisfaction of training your first model\n",
    "before worrying about more esoteric probability distributions.\n",
    "\n",
    "Aside from a few preliminary notebooks that provide a crash course\n",
    "in the basic mathematical background,\n",
    "each subsequent chapter introduces both a reasonable number of new concepts\n",
    "and provides single self-contained working examples---using real datasets.\n",
    "This presents an organizational challenge.\n",
    "Some models might logically be grouped together in a single notebook.\n",
    "And some ideas might be best taught by executing several models in succession.\n",
    "On the other hand, there is a big advantage to adhering\n",
    "to a policy of *1 working example, 1 notebook*:\n",
    "This makes it as easy as possible for you to\n",
    "start your own research projects by leveraging our code.\n",
    "Just copy a notebook and start modifying it.\n",
    "\n",
    "We will interleave the runnable code with background material as needed.\n",
    "In general, we will often err on the side of making tools\n",
    "available before explaining them fully (and we will follow up by\n",
    "explaining the background later).\n",
    "For instance, we might use *stochastic gradient descent*\n",
    "before fully explaining why it is useful or why it works.\n",
    "This helps to give practitioners the necessary\n",
    "ammunition to solve problems quickly,\n",
    "at the expense of requiring the reader\n",
    "to trust us with some curatorial decisions.\n",
    "\n",
    "This book will teach deep learning concepts from scratch.\n",
    "Sometimes, we want to delve into fine details about the models\n",
    "that would typically be hidden from the user\n",
    "by the deep learning frameworks' advanced abstractions.\n",
    "This comes up especially in the basic tutorials,\n",
    "where we want you to understand everything\n",
    "that happens in a given layer or optimizer.\n",
    "In these cases, we will often present two versions of the example:\n",
    "one where we implement everything from scratch,\n",
    "relying only on the NumPy interface and automatic differentiation,\n",
    "and another, more practical example,\n",
    "where we write succinct code using Gluon.\n",
    "Once we have taught you how some component works,\n",
    "we can just use the Gluon version in subsequent tutorials.\n",
    "\n",
    "\n",
    "### Content and Structure\n",
    "\n",
    "The book can be roughly divided into three parts,\n",
    "which are presented by different colors in :numref:`fig_book_org`:\n",
    "\n",
    "![Book structure](https://raw.githubusercontent.com/d2l-ai/d2l-en/master/img/book-org.svg)\n",
    ":label:`fig_book_org`\n",
    "\n",
    "\n",
    "* The first part covers basics and preliminaries.\n",
    ":numref:`chap_introduction` offers an introduction to deep learning.\n",
    "Then, in :numref:`chap_preliminaries`,\n",
    "we quickly bring you up to speed on the prerequisites required\n",
    "for hands-on deep learning, such as how to store and manipulate data,\n",
    "and how to apply various numerical operations based on basic concepts\n",
    "from linear algebra, calculus, and probability.\n",
    ":numref:`chap_linear` and :numref:`chap_perceptrons`\n",
    "cover the most basic concepts and techniques of deep learning,\n",
    "such as linear regression, multilayer perceptrons and regularization.\n",
    "\n",
    "* The next five chapters focus on modern deep learning techniques.\n",
    ":numref:`chap_computation` describes the various key components of deep\n",
    "learning calculations and lays the groundwork\n",
    "for us to subsequently implement more complex models.\n",
    "Next, in :numref:`chap_cnn` and :numref:`chap_modern_cnn`,\n",
    "we introduce convolutional neural networks (CNNs), powerful tools\n",
    "that form the backbone of most modern computer vision systems.\n",
    "Subsequently, in :numref:`chap_rnn` and :numref:`chap_modern_rnn`, we introduce\n",
    "recurrent neural networks (RNNs), models that exploit\n",
    "temporal or sequential structure in data, and are commonly used\n",
    "for natural language processing and time series prediction.\n",
    "In :numref:`chap_attention`, we introduce a new class of models\n",
    "that employ a technique called attention mechanisms\n",
    "and they have recently begun to displace RNNs in natural language processing.\n",
    "These sections will get you up to speed on the basic tools\n",
    "behind most modern applications of deep learning.\n",
    "\n",
    "* Part three discusses scalability, efficiency, and applications.\n",
    "First, in :numref:`chap_optimization`,\n",
    "we discuss several common optimization algorithms\n",
    "used to train deep learning models.\n",
    "The next chapter, :numref:`chap_performance` examines several key factors\n",
    "that influence the computational performance of your deep learning code.\n",
    "In :numref:`chap_cv`,\n",
    "we illustrate\n",
    "major applications of deep learning in computer vision.\n",
    "In :numref:`chap_nlp_pretrain` and :numref:`chap_nlp_app`,\n",
    "we show how to pretrain language representation models and apply\n",
    "them to natural language processing tasks.\n",
    "\n",
    "\n",
    "### Code\n",
    ":label:`sec_code`\n",
    "\n",
    "Most sections of this book feature executable code because of our belief\n",
    "in the importance of an interactive learning experience in deep learning.\n",
    "At present, certain intuitions can only be developed through trial and error,\n",
    "tweaking the code in small ways and observing the results.\n",
    "Ideally, an elegant mathematical theory might tell us\n",
    "precisely how to tweak our code to achieve a desired result.\n",
    "Unfortunately, at present, such elegant theories elude us.\n",
    "Despite our best attempts, formal explanations for various techniques\n",
    "are still lacking, both because the mathematics to characterize these models\n",
    "can be so difficult and also because serious inquiry on these topics\n",
    "has only just recently kicked into high gear.\n",
    "We are hopeful that as the theory of deep learning progresses,\n",
    "future editions of this book will be able to provide insights\n",
    "in places the present edition cannot.\n",
    "\n",
    "At times, to avoid unnecessary repetition, we encapsulate\n",
    "the frequently-imported and referred-to functions, classes, etc.\n",
    "in this book in the `utils` package. You can easily import them using \n",
    "the built-in magic command: `%load`.\n",
    "\n",
    "Most of the code in this book is based on [Deep Java Library](https://djl.ai)(DJL).\n",
    "DJL is an open-source, high-level, engine-agnostic Java framework for deep learning. \n",
    "It is designed to be easy to get started with and simple to use for Java developers. \n",
    "DJL provides a native Java development experience and functions like any other regular Java library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Audience\n",
    "\n",
    "This book is for students (undergraduate or graduate),\n",
    "engineers, and researchers, who seek a solid grasp\n",
    "of the practical techniques of deep learning.\n",
    "Because we explain every concept from scratch,\n",
    "no previous background in deep learning or machine learning is required.\n",
    "Fully explaining the methods of deep learning\n",
    "requires some mathematics and programming,\n",
    "but we will only assume that you come in with some basics,\n",
    "including (the very basics of) linear algebra, calculus, probability,\n",
    "and Python programming.\n",
    "Moreover, in the Appendix, we provide a refresher\n",
    "on most of the mathematics covered in this book.\n",
    "Most of the time, we will prioritize intuition and ideas\n",
    "over mathematical rigor.\n",
    "There are many terrific books which can lead the interested reader further.\n",
    "For instance, Linear Analysis by Bela Bollobas :cite:`Bollobas.1999`\n",
    "covers linear algebra and functional analysis in great depth.\n",
    "All of Statistics :cite:`Wasserman.2013` is a terrific guide to statistics.\n",
    "\n",
    "\n",
    "### Forum\n",
    "\n",
    "Associated with this book, we have launched a discussion forum,\n",
    "located at [discuss.d2l.ai](https://discuss.d2l.ai/).\n",
    "When you have questions on any section of the book,\n",
    "you can find the associated discussion page link at the end of each chapter.\n",
    "\n",
    "If you have any questions while using Deep Java Library, please\n",
    "[file an issue](https://github.com/deepjavalibrary/djl/issues/new/choose) with us\n",
    "or join our [slack channel](https://join.slack.com/t/deepjavalibrary/shared_invite/zt-ar91gjkz-qbXhr1l~LFGEIEeGBibT7w) for discussion.\n",
    "\n",
    "\n",
    "## Acknowledgments\n",
    "\n",
    "We are indebted to the hundreds of contributors for both\n",
    "the English and the Chinese drafts.\n",
    "They helped improve the content and offered valuable feedback.\n",
    "Specifically, we thank every contributor of this English draft\n",
    "for making it better for everyone.\n",
    "Their GitHub IDs or names are (in no particular order):\n",
    "alxnorden, avinashingit, bowen0701, brettkoonce, Chaitanya Prakash Bapat,\n",
    "cryptonaut, Davide Fiocco, edgarroman, gkutiel, John Mitro, Liang Pu,\n",
    "Rahul Agarwal, Mohamed Ali Jamaoui, Michael (Stu) Stewart, Mike Müller,\n",
    "NRauschmayr, Prakhar Srivastav, sad-, sfermigier, Sheng Zha, sundeepteki,\n",
    "topecongiro, tpdi, vermicelli, Vishaal Kapoor, Vishwesh Ravi Shrimali, YaYaB, Yuhong Chen,\n",
    "Evgeniy Smirnov, lgov, Simon Corston-Oliver, Igor Dzreyev, Ha Nguyen, pmuens,\n",
    "Andrei Lukovenko, senorcinco, vfdev-5, dsweet, Mohammad Mahdi Rahimi, Abhishek Gupta,\n",
    "uwsd, DomKM, Lisa Oakley, Bowen Li, Aarush Ahuja, Prasanth Buddareddygari, brianhendee,\n",
    "mani2106, mtn, lkevinzc, caojilin, Lakshya, Fiete Lüer, Surbhi Vijayvargeeya,\n",
    "Muhyun Kim, dennismalmgren, adursun, Anirudh Dagar, liqingnz, Pedro Larroy,\n",
    "lgov, ati-ozgur, Jun Wu, Matthias Blume, Lin Yuan, geogunow, Josh Gardner,\n",
    "Maximilian Böther, Rakib Islam, Leonard Lausen, Abhinav Upadhyay, rongruosong,\n",
    "Steve Sedlmeyer, Ruslan Baratov, Rafael Schlatter, liusy182, Giannis Pappas,\n",
    "ati-ozgur, qbaza, dchoi77, Adam Gerson, Phuc Le, Mark Atwood, christabella, vn09,\n",
    "Haibin Lin, jjangga0214, RichyChen, noelo, hansent, Giel Dops, dvincent1337, WhiteD3vil,\n",
    "Peter Kulits, codypenta, joseppinilla, ahmaurya, karolszk, heytitle, Peter Goetz, rigtorp,\n",
    "tiepvupsu, sfilip, mlxd, Kale-ab Tessera, Sanjar Adilov, MatteoFerrara, hsneto,\n",
    "Katarzyna Biesialska, Gregory Bruss, duythanhvn, paulaurel, graytowne, minhduc0711,\n",
    "sl7423, Jaedong Hwang, Yida Wang, cys4, clhm, Jean Kaddour, austinmw, trebeljahr, tbaums,\n",
    "cuongvng, pavelkomarov, vzlamal, NotAnotherSystem, J-Arun-Mani, jancio, eldarkurtic,\n",
    "the-great-shazbot, doctorcolossus, gducharme, cclauss, Daniel-Mietchen, hoonose, biagiom,\n",
    "abhinavsp0730, jonathanhrandall, ysraell, Nodar Okroshiashvili, UgurKap, Jiyang Kang,\n",
    "StevenJokes, Tomer Kaftan, liweiwp, netyster, ypandya, NishantTharani, heiligerl, SportsTHU,\n",
    "nguyenhoa93, manuel-arno-korfmann-webentwicklung, aterzis-personal, nxby, Xiaoting He, yoderj,\n",
    "mathresearch.\n",
    "\n",
    "We thank Amazon Web Services, especially Swami Sivasubramanian,\n",
    "Raju Gulabani, Charlie Bell, and Andrew Jassy for their generous support in writing this book. Without the available time, resources, discussions with colleagues, and continuous encouragement this book would not have happened.\n",
    "\n",
    "\n",
    "\n",
    "## Summary\n",
    "\n",
    "* Deep learning has revolutionized pattern recognition, introducing technology that now powers a wide range of  technologies, including computer vision, natural language processing, automatic speech recognition.\n",
    "* To successfully apply deep learning, you must understand how to cast a problem, the mathematics of modeling, the algorithms for fitting your models to data, and the engineering techniques to implement it all.\n",
    "* This book presents a comprehensive resource, including prose, figures, mathematics, and code, all in one place.\n",
    "* To answer questions related to this book, visit our forum at https://discuss.d2l.ai/.\n",
    "* All notebooks are available for download on GitHub.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "11.0.16+8-post-Ubuntu-0ubuntu120.04"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
