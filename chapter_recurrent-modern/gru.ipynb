{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Gated Recurrent Units (GRU)\n",
    ":label:`sec_gru`\n",
    "\n",
    "In :numref:`sec_bptt`,\n",
    "we discussed how gradients are calculated\n",
    "in RNNs.\n",
    "In particular we found that long products of matrices can lead\n",
    "to vanishing or exploding gradients.\n",
    "Let us briefly think about what such\n",
    "gradient anomalies mean in practice:\n",
    "\n",
    "* We might encounter a situation where an early observation is highly\n",
    "  significant for predicting all future observations. Consider the somewhat\n",
    "  contrived case where the first observation contains a checksum and the goal is\n",
    "  to discern whether the checksum is correct at the end of the sequence. In this\n",
    "  case, the influence of the first token is vital. We would like to have some\n",
    "  mechanisms for storing vital early information in a *memory cell*. Without such\n",
    "  a mechanism, we will have to assign a very large gradient to this observation,\n",
    "  since it affects all the subsequent observations.\n",
    "* We might encounter situations where some tokens carry no pertinent\n",
    "  observation. For instance, when parsing a web page there might be auxiliary\n",
    "  HTML code that is irrelevant for the purpose of assessing the sentiment\n",
    "  conveyed on the page. We would like to have some mechanism for *skipping* such\n",
    "  tokens in the latent state representation.\n",
    "* We might encounter situations where there is a logical break between parts of\n",
    "  a sequence. For instance, there might be a transition between chapters in a\n",
    "  book, or a transition between a bear and a bull market for securities. In\n",
    "  this case it would be nice to have a means of *resetting* our internal state\n",
    "  representation.\n",
    "\n",
    "A number of methods have been proposed to address this. One of the earliest is long short-term memory :cite:`Hochreiter.Schmidhuber.1997` which we\n",
    "will discuss in :numref:`sec_lstm`. The gated recurrent unit (GRU)\n",
    ":cite:`Cho.Van-Merrienboer.Bahdanau.ea.2014` is a slightly more streamlined\n",
    "variant that often offers comparable performance and is significantly faster to\n",
    "compute  :cite:`Chung.Gulcehre.Cho.ea.2014`.\n",
    "Due to its simplicity, let us start with the GRU.\n",
    "\n",
    "## Gated Hidden State\n",
    "\n",
    "The key distinction between vanilla RNNs and GRUs\n",
    "is that the latter support gating of the hidden state.\n",
    "This means that we have dedicated mechanisms for\n",
    "when a hidden state should be *updated* and\n",
    "also when it should be *reset*.\n",
    "These mechanisms are learned and they address the concerns listed above.\n",
    "For instance, if the first token is of great importance\n",
    "we will learn not to update the hidden state after the first observation.\n",
    "Likewise, we will learn to skip irrelevant temporary observations.\n",
    "Last, we will learn to reset the latent state whenever needed.\n",
    "We discuss this in detail below.\n",
    "\n",
    "\n",
    "### Reset Gate and Update Gate\n",
    "\n",
    "The first thing we need to introduce are\n",
    "the *reset gate* and the *update gate*.\n",
    "We engineer them to be vectors with entries in $(0, 1)$\n",
    "such that we can perform convex combinations.\n",
    "For instance,\n",
    "a reset gate would allow us to control how much of the previous state we might still want to remember.\n",
    "Likewise, an update gate would allow us to control how much of the new state is just a copy of the old state.\n",
    "\n",
    "We begin by engineering these gates.\n",
    ":numref:`fig_gru_1` illustrates the inputs for both\n",
    "the reset and update gates in a GRU, given the input\n",
    "of the current time step\n",
    "and the hidden state of the previous time step.\n",
    "The outputs of two gates\n",
    "are given by two fully-connected layers\n",
    "with a sigmoid activation function.\n",
    "\n",
    "![Computing the reset gate and the update gate in a GRU model.](https://raw.githubusercontent.com/d2l-ai/d2l-en/master/img/gru-1.svg)\n",
    ":label:`fig_gru_1`\n",
    "\n",
    "Mathematically,\n",
    "for a given time step $t$,\n",
    "suppose that the input is\n",
    "a minibatch\n",
    "$\\mathbf{X}_t \\in \\mathbb{R}^{n \\times d}$ (number of examples: $n$, number of inputs: $d$) and the hidden state of the previous time step is $\\mathbf{H}_{t-1} \\in \\mathbb{R}^{n \\times h}$ (number of hidden units: $h$). Then, the reset gate $\\mathbf{R}_t \\in \\mathbb{R}^{n \\times h}$ and update gate $\\mathbf{Z}_t \\in \\mathbb{R}^{n \\times h}$ are computed as follows:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{R}_t = \\sigma(\\mathbf{X}_t \\mathbf{W}_{xr} + \\mathbf{H}_{t-1} \\mathbf{W}_{hr} + \\mathbf{b}_r),\\\\\n",
    "\\mathbf{Z}_t = \\sigma(\\mathbf{X}_t \\mathbf{W}_{xz} + \\mathbf{H}_{t-1} \\mathbf{W}_{hz} + \\mathbf{b}_z),\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{W}_{xr}, \\mathbf{W}_{xz} \\in \\mathbb{R}^{d \\times h}$ and\n",
    "$\\mathbf{W}_{hr}, \\mathbf{W}_{hz} \\in \\mathbb{R}^{h \\times h}$ are weight\n",
    "parameters and $\\mathbf{b}_r, \\mathbf{b}_z \\in \\mathbb{R}^{1 \\times h}$ are\n",
    "biases. \n",
    "Note that broadcasting (see :numref:`subsec_broadcasting`) is triggered during the summation.\n",
    "We use sigmoid functions (as introduced in :numref:`sec_mlp`) to transform input values to the interval $(0, 1)$.\n",
    "\n",
    "### Candidate Hidden State\n",
    "\n",
    "Next, let us\n",
    "integrate the reset gate $\\mathbf{R}_t$ with\n",
    "the regular latent state updating mechanism\n",
    "in :eqref:`rnn_h_with_state`.\n",
    "It leads to the following\n",
    "*candidate hidden state*\n",
    "$\\tilde{\\mathbf{H}}_t \\in \\mathbb{R}^{n \\times h}$ at time step $t$:\n",
    "\n",
    "$$\\tilde{\\mathbf{H}}_t = \\tanh(\\mathbf{X}_t \\mathbf{W}_{xh} + \\left(\\mathbf{R}_t \\odot \\mathbf{H}_{t-1}\\right) \\mathbf{W}_{hh} + \\mathbf{b}_h),$$\n",
    ":eqlabel:`gru_tilde_H`\n",
    "\n",
    "where $\\mathbf{W}_{xh} \\in \\mathbb{R}^{d \\times h}$ and $\\mathbf{W}_{hh} \\in \\mathbb{R}^{h \\times h}$\n",
    "are weight parameters,\n",
    "$\\mathbf{b}_h \\in \\mathbb{R}^{1 \\times h}$\n",
    "is the bias,\n",
    "and the symbol $\\odot$ is the Hadamard (elementwise) product operator.\n",
    "Here we use a nonlinearity in the form of tanh to ensure that the values in the candidate hidden state remain in the interval $(-1, 1)$.\n",
    "\n",
    "The result is a *candidate* since we still need to incorporate the action of the update gate.\n",
    "Comparing with :eqref:`rnn_h_with_state`,\n",
    "now the influence of the previous states\n",
    "can be reduced with the\n",
    "elementwise multiplication of\n",
    "$\\mathbf{R}_t$ and $\\mathbf{H}_{t-1}$\n",
    "in :eqref:`gru_tilde_H`.\n",
    "Whenever the entries in the reset gate $\\mathbf{R}_t$ are close to 1, we recover a vanilla RNN such as in :eqref:`rnn_h_with_state`.\n",
    "For all entries of the reset gate $\\mathbf{R}_t$ that are close to 0, the candidate hidden state is the result of an MLP with $\\mathbf{X}_t$ as the input. Any pre-existing hidden state is thus *reset* to defaults.\n",
    "\n",
    ":numref:`fig_gru_2` illustrates the computational flow after applying the reset gate.\n",
    "\n",
    "![Computing the candidate hidden state in a GRU model.](https://raw.githubusercontent.com/d2l-ai/d2l-en/master/img/gru-2.svg)\n",
    ":label:`fig_gru_2`\n",
    "\n",
    "\n",
    "### Hidden State\n",
    "\n",
    "Finally, we need to incorporate the effect of the update gate $\\mathbf{Z}_t$. This determines the extent to which the new hidden state $\\mathbf{H}_t \\in \\mathbb{R}^{n \\times h}$ is just the old state $\\mathbf{H}_{t-1}$ and by how much the new candidate state $\\tilde{\\mathbf{H}}_t$ is used.\n",
    "The update gate $\\mathbf{Z}_t$ can be used for this purpose, simply by taking elementwise convex combinations between both $\\mathbf{H}_{t-1}$ and $\\tilde{\\mathbf{H}}_t$.\n",
    "This leads to the final update equation for the GRU:\n",
    "\n",
    "$$\\mathbf{H}_t = \\mathbf{Z}_t \\odot \\mathbf{H}_{t-1}  + (1 - \\mathbf{Z}_t) \\odot \\tilde{\\mathbf{H}}_t.$$\n",
    "\n",
    "\n",
    "Whenever the update gate $\\mathbf{Z}_t$ is close to 1, we simply retain the old state. In this case the information from $\\mathbf{X}_t$ is essentially ignored, effectively skipping time step $t$ in the dependency chain. In contrast, whenever $\\mathbf{Z}_t$ is close to 0, the new latent state $\\mathbf{H}_t$ approaches the candidate latent state $\\tilde{\\mathbf{H}}_t$. These designs can help us cope with the vanishing gradient problem in RNNs and better capture dependencies for sequences with large time step distances.\n",
    "For instance,\n",
    "if the update gate has been close to 1\n",
    "for all the time steps of an entire subsequence,\n",
    "the old hidden state at the time step of its beginning\n",
    "will be easily retained and passed\n",
    "to its end,\n",
    "regardless of the length of the subsequence.\n",
    "\n",
    "\n",
    "\n",
    ":numref:`fig_gru_3` illustrates the computational flow after the update gate is in action.\n",
    "\n",
    "![Computing the hidden state in a GRU model.](https://raw.githubusercontent.com/d2l-ai/d2l-en/master/img/gru-3.svg)\n",
    ":label:`fig_gru_3`\n",
    "\n",
    "\n",
    "In summary, GRUs have the following two distinguishing features:\n",
    "\n",
    "* Reset gates help capture short-term dependencies in sequences.\n",
    "* Update gates help capture long-term dependencies in sequences.\n",
    "\n",
    "## Implementation from Scratch\n",
    "\n",
    "To gain a better understanding of the GRU model, let us implement it from scratch. We begin by reading the time machine dataset that we used in :numref:`sec_rnn_scratch`. The code for reading the dataset is given below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "   <div id=\"47paob\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "       if(!window.letsPlotCallQueue) {\n",
       "           window.letsPlotCallQueue = [];\n",
       "       }; \n",
       "       window.letsPlotCall = function(f) {\n",
       "           window.letsPlotCallQueue.push(f);\n",
       "       };\n",
       "       (function() {\n",
       "           var script = document.createElement(\"script\");\n",
       "           script.type = \"text/javascript\";\n",
       "           script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v2.4.0/js-package/distr/lets-plot.min.js\";\n",
       "           script.onload = function() {\n",
       "               window.letsPlotCall = function(f) {f();};\n",
       "               window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "               window.letsPlotCallQueue = [];\n",
       "               \n",
       "               \n",
       "           };\n",
       "           script.onerror = function(event) {\n",
       "               window.letsPlotCall = function(f) {};\n",
       "               window.letsPlotCallQueue = [];\n",
       "               var div = document.createElement(\"div\");\n",
       "               div.style.color = 'darkred';\n",
       "               div.textContent = 'Error loading Lets-Plot JS';\n",
       "               document.getElementById(\"47paob\").appendChild(div);\n",
       "           };\n",
       "           var e = document.getElementById(\"47paob\");\n",
       "           e.appendChild(script);\n",
       "       })();\n",
       "   </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%use @file[../djl.json]\n",
    "%use lets-plot\n",
    "@file:DependsOn(\"../D2J-1.0-SNAPSHOT.jar\")\n",
    "import jp.live.ugai.d2j.timemachine.RNNModelScratch\n",
    "import jp.live.ugai.d2j.timemachine.TimeMachine.trainCh8\n",
    "import jp.live.ugai.d2j.timemachine.TimeMachineDataset\n",
    "import jp.live.ugai.d2j.timemachine.Vocab\n",
    "import jp.live.ugai.d2j.RNNModel\n",
    "import jp.live.ugai.d2j.StopWatch\n",
    "import jp.live.ugai.d2j.Accumulator\n",
    "import jp.live.ugai.d2j.Training\n",
    "\n",
    "// %load ../utils/djl-imports\n",
    "// %load ../utils/plot-utils\n",
    "// %load ../utils/Functions.java\n",
    "// %load ../utils/Functions.java\n",
    "// %load ../utils/PlotUtils.java\n",
    "\n",
    "// %load ../utils/StopWatch.java\n",
    "// %load ../utils/Accumulator.java\n",
    "// %load ../utils/Animator.java\n",
    "// %load ../utils/Training.java\n",
    "// %load ../utils/timemachine/Vocab.java\n",
    "// %load ../utils/timemachine/RNNModel.java\n",
    "// %load ../utils/timemachine/RNNModelScratch.java\n",
    "// %load ../utils/timemachine/TimeMachine.java\n",
    "// %load ../utils/timemachine/TimeMachineDataset.java\n",
    "import kotlin.random.Random\n",
    "import kotlin.collections.List\n",
    "import kotlin.collections.Map\n",
    "import kotlin.Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val manager = NDManager.newBaseManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UniqTokens: 29\n"
     ]
    }
   ],
   "source": [
    "val batchSize = 32\n",
    "val numSteps = 35\n",
    "\n",
    "val dataset = TimeMachineDataset.Builder()\n",
    "        .setManager(manager)\n",
    "        .setMaxTokens(10000)\n",
    "        .setSampling(batchSize, false)\n",
    "        .setSteps(numSteps)\n",
    "        .build()\n",
    "dataset.prepare()\n",
    "val vocab = dataset.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 3
   },
   "source": [
    "### Initializing Model Parameters\n",
    "\n",
    "The next step is to initialize the model parameters.\n",
    "We draw the weights from a Gaussian distribution\n",
    "with standard deviation to be 0.01 and set the bias to 0. The hyperparameter `num_hiddens` defines the number of hidden units.\n",
    "We instantiate all weights and biases relating to the update gate, the reset gate, the candidate hidden state,\n",
    "and the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    fun normal(shape: Shape, device: Device): NDArray {\n",
    "        return manager.randomNormal(0.0f, 0.01f, shape, DataType.FLOAT32, device)\n",
    "    }\n",
    "\n",
    "    fun three(numInputs: Int, numHiddens: Int, device: Device): NDList {\n",
    "        return NDList(\n",
    "            normal(Shape(numInputs.toLong(), numHiddens.toLong()), device),\n",
    "            normal(Shape(numHiddens.toLong(), numHiddens.toLong()), device),\n",
    "            manager.zeros(Shape(numHiddens.toLong()), DataType.FLOAT32, device)\n",
    "        )\n",
    "    }\n",
    "\n",
    "    fun getParams(vocabSize: Int, numHiddens: Int, device: Device): NDList {\n",
    "        // Update gate parameters\n",
    "        var temp = three(vocabSize, numHiddens, device)\n",
    "        val W_xz = temp[0]\n",
    "        val W_hz = temp[1]\n",
    "        val b_z = temp[2]\n",
    "\n",
    "        // Reset gate parameters\n",
    "        temp = three(vocabSize, numHiddens, device)\n",
    "        val W_xr = temp[0]\n",
    "        val W_hr = temp[1]\n",
    "        val b_r = temp[2]\n",
    "\n",
    "        // Candidate hidden state parameters\n",
    "        temp = three(vocabSize, numHiddens, device)\n",
    "        val W_xh = temp[0]\n",
    "        val W_hh = temp[1]\n",
    "        val b_h = temp[2]\n",
    "\n",
    "        // Output layer parameters\n",
    "        val W_hq = normal(Shape(numHiddens.toLong(), vocabSize.toLong()), device)\n",
    "        val b_q: NDArray = manager.zeros(Shape(vocabSize.toLong()), DataType.FLOAT32, device)\n",
    "\n",
    "        // Attach gradients\n",
    "        val params = NDList(W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q)\n",
    "        for (param in params) {\n",
    "            param.setRequiresGradient(true)\n",
    "        }\n",
    "        return params\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "### Defining the Model\n",
    "\n",
    "Now we will define the hidden state initialization function `init_gru_state`. Just like the `init_rnn_state` function defined in :numref:`sec_rnn_scratch`, this function returns a tensor with a shape (batch size, number of hidden units) whose values are all zeros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    fun initGruState(batchSize: Int, numHiddens: Int, device: Device): NDList {\n",
    "        return NDList(manager.zeros(Shape(batchSize.toLong(), numHiddens.toLong()), DataType.FLOAT32, device))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 9
   },
   "source": [
    "Now we are ready to define the GRU model.\n",
    "Its structure is the same as that of the basic RNN cell, except that the update equations are more complex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    fun gru(inputs: NDArray, state: NDList, params: NDList): Pair<NDArray, NDList> {\n",
    "        val W_xz = params[0]\n",
    "        val W_hz = params[1]\n",
    "        val b_z = params[2]\n",
    "        val W_xr = params[3]\n",
    "        val W_hr = params[4]\n",
    "        val b_r = params[5]\n",
    "        val W_xh = params[6]\n",
    "        val W_hh = params[7]\n",
    "        val b_h = params[8]\n",
    "        val W_hq = params[9]\n",
    "        val b_q = params[10]\n",
    "        var H = state[0]\n",
    "        val outputs = NDList()\n",
    "        var X: NDArray\n",
    "        var Y: NDArray\n",
    "        var Z: NDArray\n",
    "        var R: NDArray\n",
    "        var H_tilda: NDArray\n",
    "        for (i in 0 until inputs.size(0)) {\n",
    "            X = inputs[i]\n",
    "            Z = Activation.sigmoid(X.dot(W_xz).add(H.dot(W_hz).add(b_z)))\n",
    "            R = Activation.sigmoid(X.dot(W_xr).add(H.dot(W_hr).add(b_r)))\n",
    "            H_tilda = Activation.tanh(X.dot(W_xh).add(R.mul(H).dot(W_hh).add(b_h)))\n",
    "            H = Z.mul(H).add(Z.mul(-1).add(1).mul(H_tilda))\n",
    "            Y = H.dot(W_hq).add(b_q)\n",
    "            outputs.add(Y)\n",
    "        }\n",
    "        return Pair(if (outputs.size > 1) NDArrays.concat(outputs) else outputs[0], NDList(H))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "### Training and Prediction\n",
    "\n",
    "Training and prediction work in exactly the same manner as in :numref:`sec_rnn_scratch`.\n",
    "After training,\n",
    "we print out the perplexity on the training set\n",
    "and the predicted sequence following\n",
    "the provided prefixes \"time traveller\" and \"traveller\", respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 : 17.271841167371946\n",
      "20 : 15.558340521802963\n",
      "30 : 12.932673074172952\n",
      "40 : 11.517789793633652\n",
      "50 : 10.859578228883809\n",
      "60 : 10.396758730356678\n",
      "70 : 10.022118791155375\n",
      "80 : 9.672249909703204\n",
      "90 : 9.318414060908909\n",
      "100 : 8.975387667401227\n",
      "110 : 8.65112473599814\n",
      "120 : 8.357729672118614\n",
      "130 : 8.083047618563453\n",
      "140 : 7.802219653388491\n",
      "150 : 7.5133214511495\n",
      "160 : 7.332238049111319\n",
      "170 : 6.954259703723563\n",
      "180 : 6.6869890462785415\n",
      "190 : 6.544543125433988\n",
      "200 : 6.182894323830925\n",
      "210 : 5.889348634516324\n",
      "220 : 5.567831734215796\n",
      "230 : 5.2998297178611535\n",
      "240 : 4.866570091210992\n",
      "250 : 4.444854192998585\n",
      "260 : 4.0194286519449225\n",
      "270 : 3.744644844403568\n",
      "280 : 3.3098190775001353\n",
      "290 : 2.8249033869116666\n",
      "300 : 2.6687337604462646\n",
      "310 : 2.1520669592613304\n",
      "320 : 1.929144613811204\n",
      "330 : 1.5491798151163925\n",
      "340 : 1.5598138835102993\n",
      "350 : 1.5115303479780329\n",
      "360 : 1.1494822851989233\n",
      "370 : 1.156347623632971\n",
      "380 : 1.0861530997355475\n",
      "390 : 1.2570793742403263\n",
      "400 : 1.0623924293646037\n",
      "410 : 1.0486809975994094\n",
      "420 : 1.208406373030951\n",
      "430 : 1.0431319416972675\n",
      "440 : 1.0357904060767331\n",
      "450 : 1.0309235010206734\n",
      "460 : 1.1241446315793604\n",
      "470 : 1.0383652253209972\n",
      "480 : 1.0279154988512307\n",
      "490 : 1.0238969549199988\n",
      "500 : 1.0214552456796164\n",
      "perplexity: 1.0, 1342.8 tokens/sec on cpu()\n",
      "\n",
      "time traveller for say i jever betyeery when thria s and thisgso\n",
      "traveller firefyedian thone his laps pat ond latter time as\n"
     ]
    }
   ],
   "source": [
    "    val vocabSize = vocab.length()\n",
    "    val numHiddens = 256\n",
    "    val device = manager.device\n",
    "    val numEpochs = Integer.getInteger(\"MAX_EPOCH\", 500)\n",
    "\n",
    "    val lr = 1\n",
    "    val model = RNNModelScratch(vocabSize, numHiddens, device, ::getParams, ::initGruState, ::gru)\n",
    "    trainCh8(model, dataset, vocab, lr, numEpochs, device, false, manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 14
   },
   "source": [
    "## Concise Implementation\n",
    "\n",
    "In high-level APIs,\n",
    "we can directly\n",
    "instantiate a GPU model.\n",
    "This encapsulates all the configuration detail that we made explicit above.\n",
    "The code is significantly faster as it uses compiled operators rather than Python for many details that we spelled out before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 : 17.2957388424852\n",
      "20 : 15.612232199921735\n",
      "30 : 12.95745128904966\n",
      "40 : 11.511394359966346\n",
      "50 : 10.831249084171018\n",
      "60 : 10.35717830890521\n",
      "70 : 9.973543260723103\n",
      "80 : 9.612699276279152\n",
      "90 : 9.265637751238879\n",
      "100 : 8.945641845277848\n",
      "110 : 8.647103269097705\n",
      "120 : 8.356512771273225\n",
      "130 : 8.094383229732669\n",
      "140 : 7.832642282375142\n",
      "150 : 7.573023341670194\n",
      "160 : 7.303130181751629\n",
      "170 : 7.073852246195889\n",
      "180 : 6.777475831054104\n",
      "190 : 6.590961527373202\n",
      "200 : 6.279959571682691\n",
      "210 : 5.953709416281121\n",
      "220 : 5.71520063433334\n",
      "230 : 5.399517493219079\n",
      "240 : 5.152538053090552\n",
      "250 : 4.820729907284465\n",
      "260 : 4.452173965108438\n",
      "270 : 4.0641103697376195\n",
      "280 : 3.7981879592290517\n",
      "290 : 3.3607761221456802\n",
      "300 : 3.009786339446698\n",
      "310 : 2.714685723469379\n",
      "320 : 2.2613384639440692\n",
      "330 : 1.9874101788284821\n",
      "340 : 1.784293217582859\n",
      "350 : 1.4896686084430264\n",
      "360 : 1.3501950621358667\n",
      "370 : 1.4154513535272335\n",
      "380 : 1.1388849442235562\n",
      "390 : 1.2025281479317587\n",
      "400 : 1.0835807950734486\n",
      "410 : 1.0702961199199543\n",
      "420 : 1.0684370914681118\n",
      "430 : 1.0494992807258277\n",
      "440 : 1.041679159437669\n",
      "450 : 1.0392354821334366\n",
      "460 : 1.033572103686121\n",
      "470 : 1.0298184821877419\n",
      "480 : 1.0276765145683013\n",
      "490 : 1.0262599623949642\n",
      "500 : 1.0441814589705098\n",
      "perplexity: 1.0, 14646.4 tokens/sec on cpu()\n",
      "\n",
      "time traveller after the pauserequired for the proper assimilati\n",
      "traveller affout in his hroe ale allopr wele as so expen a \n"
     ]
    }
   ],
   "source": [
    "    val gruLayer = GRU.builder()\n",
    "        .setNumLayers(1)\n",
    "        .setStateSize(numHiddens)\n",
    "        .optReturnState(true)\n",
    "        .optBatchFirst(false)\n",
    "        .build()\n",
    "    val modelConcise = RNNModel(gruLayer, vocab.length())\n",
    "    trainCh8(modelConcise, dataset, vocab, lr, numEpochs, device, false, manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 17
   },
   "source": [
    "## Summary\n",
    "\n",
    "* Gated RNNs can better capture dependencies for sequences with large time step distances.\n",
    "* Reset gates help capture short-term dependencies in sequences.\n",
    "* Update gates help capture long-term dependencies in sequences.\n",
    "* GRUs contain basic RNNs as their extreme case whenever the reset gate is switched on. They can also skip subsequences by turning on the update gate.\n",
    "\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Assume that we only want to use the input at time step $t'$ to predict the output at time step $t > t'$. What are the best values for the reset and update gates for each time step?\n",
    "1. Adjust the hyperparameters and analyze the their influence on running time, perplexity, and the output sequence.\n",
    "1. Compare runtime, perplexity, and the output strings for `rnn.RNN` and `rnn.GRU` implementations with each other.\n",
    "1. What happens if you implement only parts of a GRU, e.g., with only a reset gate or only an update gate?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "codemirror_mode": "text/x-kotlin",
   "file_extension": ".kt",
   "mimetype": "text/x-kotlin",
   "name": "kotlin",
   "nbconvert_exporter": "",
   "pygments_lexer": "kotlin",
   "version": "1.8.0-dev-707"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
