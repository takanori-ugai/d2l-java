{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# File I/O\n",
    "\n",
    "So far we discussed how to process data and how\n",
    "to build, train, and test deep learning models.\n",
    "However, at some point, we will hopefully be happy enough\n",
    "with the learned models that we will want\n",
    "to save the results for later use in various contexts\n",
    "(perhaps even to make predictions in deployment).\n",
    "Additionally, when running a long training process,\n",
    "the best practice is to periodically save intermediate results (checkpointing)\n",
    "to ensure that we do not lose several days worth of computation\n",
    "if we trip over the power cord of our server.\n",
    "Thus it is time we learned how to load and store\n",
    "both individual weight vectors and entire models.\n",
    "This section addresses both issues.\n",
    "\n",
    "## Loading and Saving Tensors\n",
    "\n",
    "For individual tensors, we can convert NDArrays into\n",
    "`byte[]`s by calling their `encode()` function.\n",
    "We can then convert them back into NDArrays by calling\n",
    "the NDArray `decode()` function and passing in \n",
    "an `NDManager`(to manage the created NDArray) and `byte[]` (the wanted tensor).\n",
    "\n",
    "We can then use `FileInputStream` and `FileOutputStream` to \n",
    "read and write these to files respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%use @file[../djl.json]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "origin_pos": 1,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ND: (4) cpu() int32\n",
       "[ 0,  1,  2,  3]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val manager = NDManager.newBaseManager()\n",
    "\n",
    "val x = manager.arange(4)\n",
    "FileOutputStream(\"x-file\").use { fos ->\n",
    "    fos.write(x.encode())\n",
    "}\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "We can now read this data from the stored file back into memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "origin_pos": 5,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ND: (4) cpu() int32\n",
       "[ 0,  1,  2,  3]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var x2 : NDArray\n",
    "FileInputStream(\"x-file\").use { fis ->\n",
    "    // We use the `Utils` method `toByteArray()` to read \n",
    "    // from a `FileInputStream` and return it as a `byte[]`.\n",
    "    x2 = NDArray.decode(manager, fis.readAllBytes())  \n",
    "}\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also store `NDList` into a file and load it back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDList size: 2\n",
       "0 : (4) int32\n",
       "1 : (4) int32\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var list = NDList(x, x2)\n",
    "FileOutputStream(\"x-file\").use { fos ->\n",
    "    fos.write(list.encode());\n",
    "}\n",
    "FileInputStream(\"x-file\").use { fis -> \n",
    "    list = NDList.decode(manager, fis.readAllBytes());\n",
    "}\n",
    "list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "## Model Parameters\n",
    "\n",
    "Saving individual weight vectors (or other tensors) is useful,\n",
    "but it gets very tedious if we want to save\n",
    "(and later load) an entire model.\n",
    "After all, we might have hundreds of\n",
    "parameter groups sprinkled throughout.\n",
    "For this reason the framework provides built-in functionality\n",
    "to load and save entire networks.\n",
    "An important detail to note is that this\n",
    "saves model *parameters* and not the entire model.\n",
    "For example, if we have a 3-layer MLP,\n",
    "we need to specify the *architecture* separately.\n",
    "The reason for this is that the models themselves can contain arbitrary code,\n",
    "hence they cannot be serialized as naturally.\n",
    "Thus, in order to reinstate a model, we need\n",
    "to generate the architecture in code\n",
    "and then load the parameters from disk.\n",
    "Let us start with our familiar MLP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "origin_pos": 17,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ND: (2, 10) cpu() float32\n",
       "[[ 0.0824, -0.0867, -0.6448,  1.4992, -0.1772,  0.3954, -0.4888,  0.0137, -0.9857, -0.5504],\n",
       " [-0.066 ,  0.1233, -0.8066,  1.7184,  0.0047,  0.7531, -0.7659,  0.3363, -0.7143, -0.5668],\n",
       "]\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun createMLP() :  SequentialBlock {\n",
    "    val mlp = SequentialBlock()\n",
    "    mlp.add(Linear.builder().setUnits(256).build())\n",
    "    mlp.add(Activation.reluBlock())\n",
    "    mlp.add(Linear.builder().setUnits(10).build())\n",
    "    return mlp\n",
    "}\n",
    "\n",
    "val original = createMLP()\n",
    "\n",
    "val x = manager.randomUniform(0.0f, 1.0f, Shape(2, 5))\n",
    "\n",
    "original.initialize(manager, DataType.FLOAT32, x.getShape());\n",
    "\n",
    "val ps = ParameterStore(manager, false);\n",
    "val y = original.forward(ps, NDList(x), false).singletonOrThrow()\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "Next, we store the parameters of the model as a file with the name `mlp.param`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "origin_pos": 21,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [],
   "source": [
    "// Save file\n",
    "val mlpParamFile = File(\"mlp.param\");\n",
    "val os = DataOutputStream(Files.newOutputStream(mlpParamFile.toPath()));\n",
    "original.saveParameters(os);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 24
   },
   "source": [
    "To recover the model, we instantiate a clone\n",
    "of the original MLP model.\n",
    "Instead of randomly initializing the model parameters,\n",
    "we read the parameters stored in the file directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "origin_pos": 25,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [],
   "source": [
    "// Create duplicate of network architecture\n",
    "val clone = createMLP();\n",
    "// Load Parameters\n",
    "clone.loadParameters(manager, DataInputStream(Files.newInputStream(mlpParamFile.toPath())));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us directly compare the parameters of both models. We get the `Parameter`'s respective array at each index for both `PairList`s and then compare the two.\n",
    "\n",
    "\n",
    "Note that we cannot compare the `Parameter`'s directly. When we load the `Parameter`, a new unique id is generated for it. Instead, we can check that the `NDArray`s are equal.\n",
    "\n",
    "They should be identical if loaded properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True True "
     ]
    }
   ],
   "source": [
    "// Original model's parameters\n",
    "val originalParams = original.getParameters();\n",
    "// Loaded model's parameters\n",
    "val loadedParams = clone.getParameters();\n",
    "\n",
    "for (i in 0 until originalParams.size()) {\n",
    "    if (originalParams.valueAt(i).getArray().equals(loadedParams.valueAt(i).getArray())) {\n",
    "        print(\"True \");\n",
    "    } else {\n",
    "        print(\"False \");\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 28
   },
   "source": [
    "Since both instances have the same model parameters,\n",
    "the computation result of the same input `x` should be the same.\n",
    "Let us verify this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "origin_pos": 29,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val yClone = clone.forward(ps, NDList(x), false).singletonOrThrow();\n",
    "\n",
    "y.equals(yClone);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 32
   },
   "source": [
    "## Summary\n",
    "\n",
    "* The `decode` and `encode` functions along with `FileStreams` can be used to perform File I/O for tensor objects.\n",
    "* Saving the architecture has to be done in code rather than in parameters.\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Even if there is no need to deploy trained models to a different device, what are the practical benefits of storing model parameters?\n",
    "1. Assume that we want to reuse only parts of a network to be incorporated into a network of a *different* architecture. How would you go about using, say the first two layers from a previous network in a new network.\n",
    "1. How would you go about saving network architecture and parameters? What restrictions would you impose on the architecture?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "codemirror_mode": "text/x-kotlin",
   "file_extension": ".kt",
   "mimetype": "text/x-kotlin",
   "name": "kotlin",
   "nbconvert_exporter": "",
   "pygments_lexer": "kotlin",
   "version": "1.8.0-dev-707"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
