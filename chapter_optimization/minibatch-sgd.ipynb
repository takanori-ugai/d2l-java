{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minibatch Stochastic Gradient Descent\n",
    ":label:`sec_minibatch_sgd`\n",
    "\n",
    "So far we encountered two extremes in the approach to gradient based learning: :numref:`sec_gd` uses the full dataset to compute gradients and to update parameters, one pass at a time. Conversely :numref:`sec_sgd` processes one observation at a time to make progress. Each of them has its own drawbacks. Gradient Descent is not particularly *data efficient* whenever data is very similar. Stochastic Gradient Descent is not particularly *computationally efficient* since CPUs and GPUs cannot exploit the full power of vectorization. This suggests that there might be a happy medium, and in fact, that's what we have been using so far in the examples we discussed. \n",
    "\n",
    "## Vectorization and Caches\n",
    "\n",
    "At the heart of the decision to use minibatches is computational efficiency. This is most easily understood when considering parallelization to multiple GPUs and multiple servers. In this case we need to send at least one image to each GPU. With 8 GPUs per server and 16 servers we already arrive at a minibatch size of 128.\n",
    "\n",
    "Things are a bit more subtle when it comes to single GPUs or even CPUs. These devices have multiple types of memory, often multiple type of compute units and different bandwidth constraints between them. For instance, a CPU has a small number of registers and then L1, L2 and in some cases even L3 cache (which is shared between the different processor cores). These caches are of increasing size and latency (and at the same time they are of decreasing bandwidth). Suffice it to say, the processor is capable of performing many more operations than what the main memory interface is able to provide. \n",
    "\n",
    "* A 2GHz CPU with 16 cores and AVX-512 vectorization can process up to $2 \\cdot 10^9 \\cdot 16 \\cdot 32 = 10^{12}$ bytes per second. The capability of GPUs easily exceeds this number by a factor of 100. On the other hand, a midrange server processor might not have much more than 100 GB/s bandwidth, i.e., less than one tenth of what would be required to keep the processor fed. To make matters worse, not all memory access is created equal: first, memory interfaces are typically 64 bit wide or wider (e.g., on GPUs up to 384 bit), hence reading a single byte incurs the cost of a much wider access. \n",
    "* There is significant overhead for the first access whereas sequential access is relatively cheap (this is often called a burst read). There are many more things to keep in mind, such as caching when we have multiple sockets, chiplets and other structures. A detailed discussion of this is beyond the scope of this section. See e.g., this [Wikipedia article](https://en.wikipedia.org/wiki/Cache_hierarchy) for a more in-depth discussion.\n",
    "\n",
    "The way to alleviate these constraints is to use a hierarchy of CPU caches which are actually fast enough to supply the processor with data. This is *the* driving force behind batching in deep learning. To keep matters simple, consider matrix-matrix multiplication, say $\\mathbf{A} = \\mathbf{B}\\mathbf{C}$. We have a number of options for calculating $\\mathbf{A}$. For instance we could try the following:\n",
    "\n",
    "1. We could compute $\\mathbf{A}_{ij} = \\mathbf{B}_{i,:} \\mathbf{C}_{:,j}^\\top$, i.e., we could compute it element-wise by means of dot products.\n",
    "1. We could compute $\\mathbf{A}_{:,j} = \\mathbf{B} \\mathbf{C}_{:,j}^\\top$, i.e., we could compute it one column at a time. Likewise we could compute $\\mathbf{A}$ one row $\\mathbf{A}_{i,:}$ at a time. \n",
    "1. We could simply compute $\\mathbf{A} = \\mathbf{B} \\mathbf{C}$. \n",
    "1. We could break $\\mathbf{B}$ and $\\mathbf{C}$ into smaller block matrices and compute $\\mathbf{A}$ one block at a time. \n",
    "\n",
    "If we follow the first option, we will need to copy one row and one column vector into the CPU each time we want to compute an element $\\mathbf{A}_{ij}$. Even worse, due to the fact that matrix elements are aligned sequentially we are thus required to access many disjoint locations for one of the two vectors as we read them from memory. The second option is much more favorable. In it, we are able to keep the column vector $\\mathbf{C}_{:,j}$ in the CPU cache while we keep on traversing through $B$. This halves the memory bandwidth requirement with correspondingly faster access. Of course, option 3 is most desirable. Unfortunately, most matrices might not entirely fit into cache (this is what we are discussing after all). However, option 4 offers a practically useful alternative: we can move blocks of the matrix into cache and multiply them locally. Optimized libraries take care of this for us. Let us have a look at how efficient these operations are in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "   <div id=\"eMAolc\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "       if(!window.letsPlotCallQueue) {\n",
       "           window.letsPlotCallQueue = [];\n",
       "       }; \n",
       "       window.letsPlotCall = function(f) {\n",
       "           window.letsPlotCallQueue.push(f);\n",
       "       };\n",
       "       (function() {\n",
       "           var script = document.createElement(\"script\");\n",
       "           script.type = \"text/javascript\";\n",
       "           script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v2.4.0/js-package/distr/lets-plot.min.js\";\n",
       "           script.onload = function() {\n",
       "               window.letsPlotCall = function(f) {f();};\n",
       "               window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "               window.letsPlotCallQueue = [];\n",
       "               \n",
       "               \n",
       "           };\n",
       "           script.onerror = function(event) {\n",
       "               window.letsPlotCall = function(f) {};\n",
       "               window.letsPlotCallQueue = [];\n",
       "               var div = document.createElement(\"div\");\n",
       "               div.style.color = 'darkred';\n",
       "               div.textContent = 'Error loading Lets-Plot JS';\n",
       "               document.getElementById(\"eMAolc\").appendChild(div);\n",
       "           };\n",
       "           var e = document.getElementById(\"eMAolc\");\n",
       "           e.appendChild(script);\n",
       "       })();\n",
       "   </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%use @file[../djl-pytoch-0.18.0.json]\n",
    "%use lets-plot\n",
    "@file:DependsOn(\"../D2J-1.0-SNAPSHOT.jar\")\n",
    "//import jp.live.ugai.d2j.attention.Chap10Utils\n",
    "import org.jetbrains.letsPlot.intern.Plot\n",
    "import jp.live.ugai.d2j.util.StopWatch\n",
    "import jp.live.ugai.d2j.util.Training\n",
    "import jp.live.ugai.d2j.util.Accumulator\n",
    "// %load ../utils/djl-imports\n",
    "// %load ../utils/plot-utils\n",
    "// %load ../utils/Functions.java\n",
    "// %load ../utils/StopWatch.java\n",
    "// %load ../utils/Training.java\n",
    "// %load ../utils/Accumulator.java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ai.djl.basicdataset.tabular.*\n",
    "import ai.djl.basicdataset.cv.classification.*\n",
    "// import org.apache.commons.lang3.ArrayUtils;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "var manager = NDManager.newBaseManager();\n",
    "val stopWatch = StopWatch();\n",
    "var A = manager.zeros(Shape(256, 256));\n",
    "val B = manager.randomNormal(Shape(256, 256));\n",
    "val C = manager.randomNormal(Shape(256, 256));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Element-wise assignment simply iterates over all rows and columns of $\\mathbf{B}$ and $\\mathbf{C}$ respectively to assign the value to $\\mathbf{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1147689"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Compute A = B C one element at a time\n",
    "stopWatch.start();\n",
    "for (i in 0 until 256) {\n",
    "    for (j in 0 until 256) {\n",
    "        A.set(NDIndex(i.toLong(), j.toLong()), \n",
    "              B.get(NDIndex(\"$i, :\")).dot(C.get(NDIndex(\":, $j\"))))\n",
    "    }\n",
    "}\n",
    "stopWatch.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A faster strategy is to perform column-wise assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0248393"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Compute A = B C one column at a time\n",
    "stopWatch.start();\n",
    "for (j in 0 until 256) {\n",
    "    A.set(NDIndex(\":, $j\"), B.matMul(C.get(NDIndex(\":, $j\"))))\n",
    "}\n",
    "stopWatch.stop();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, the most effective manner is to perform the entire operation in one block. Let us see what the respective speed of the operations is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Performance in Gigaflops: element 0.946, column 80.518, full 1293.996"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Compute A = B C in one go\n",
    "stopWatch.start();\n",
    "A = B.dot(C);\n",
    "stopWatch.stop();\n",
    "\n",
    "// Multiply and add count as separate operations (fused in practice)\n",
    "val gigaflops = mutableListOf<Float>()\n",
    "for (i in 0 until stopWatch.times.size) {\n",
    "    gigaflops.add(2 / stopWatch.times.get(i).toFloat())\n",
    "}\n",
    "\"Performance in Gigaflops: element %.3f, column %.3f, full %.3f\".format(gigaflops[0], gigaflops[1], gigaflops[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minibatches \n",
    "\n",
    ":label:`sec_minibatches`\n",
    "\n",
    "In the past we took it for granted that we would read *minibatches* of data rather than single observations to update parameters. We now give a brief justification for it. Processing single observations requires us to perform many single matrix-vector (or even vector-vector) multiplications, which is quite expensive and which incurs a significant overhead on behalf of the underlying deep learning framework. This applies both to evaluating a network when applied to data (often referred to as inference) and when computing gradients to update parameters. That is, this applies whenever we perform $\\mathbf{w} \\leftarrow \\mathbf{w} - \\eta_t \\mathbf{g}_t$ where \n",
    "\n",
    "$$\\mathbf{g}_t = \\partial_{\\mathbf{w}} f(\\mathbf{x}_{t}, \\mathbf{w})$$\n",
    "\n",
    "We can increase the *computational* efficiency of this operation by applying it to a minibatch of observations at a time. That is, we replace the gradient $\\mathbf{g}_t$ over a single observation by one over a small batch\n",
    "\n",
    "$$\\mathbf{g}_t = \\partial_{\\mathbf{w}} \\frac{1}{|\\mathcal{B}_t|} \\sum_{i \\in \\mathcal{B}_t} f(\\mathbf{x}_{i}, \\mathbf{w})$$\n",
    "\n",
    "Let us see what this does to the statistical properties of $\\mathbf{g}_t$: since both $\\mathbf{x}_t$ and also all elements of the minibatch $\\mathcal{B}_t$ are drawn uniformly at random from the training set, the expectation of the gradient remains unchanged. The variance, on the other hand, is reduced significantly. Since the minibatch gradient is composed of $b := |\\mathcal{B}_t|$ independent gradients which are being averaged, its standard deviation is reduced by a factor of $b^{-\\frac{1}{2}}$. This, by itself, is a good thing, since it means that the updates are more reliably aligned with the full gradient. \n",
    "\n",
    "Naively this would indicate that choosing a large minibatch $\\mathcal{B}_t$ would be universally desirable. Alas, after some point, the additional reduction in standard deviation is minimal when compared to the linear increase in computational cost. In practice we pick a minibatch that is large enough to offer good computational efficiency while still fitting into the memory of a GPU. To illustrate the savings let us have a look at some code. In it we perform the same matrix-matrix multiplication, but this time broken up into \"minibatches\" of 64 columns at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Performance in Gigaflops: block 107.494\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopWatch.start();\n",
    "for (j in 0 until 256 step 64 ) {\n",
    "    A.set(NDIndex(\":, $j:${j+64}\"), \n",
    "        B.dot(C.get(NDIndex(\":, $j:${j+64}\"))))\n",
    "}\n",
    "stopWatch.stop();\n",
    "\n",
    "\"Performance in Gigaflops: block %.3f\\n\".format(2 / stopWatch.times.get(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the computation on the minibatch is essentially as efficient as on the full matrix. A word of caution is in order. In :numref:`sec_batch_norm` we used a type of regularization that was heavily dependent on the amount of variance in a minibatch. As we increase the latter, the variance decreases and with it the benefit of the noise-injection due to batch normalization. See e.g., :cite:`Ioffe.2017` for details on how to rescale and compute the appropriate terms. \n",
    "\n",
    "## Reading the Dataset\n",
    "\n",
    "Let us have a look at how minibatches are efficiently generated from data. In the following we use a dataset developed by NASA to test the wing [noise from different aircraft](https://archive.ics.uci.edu/ml/datasets/Airfoil+Self-Noise) to compare these optimization algorithms. For convenience we only use the first $1,500$ examples. The data is whitened for preprocessing, i.e., we remove the mean and rescale the variance to $1$ per coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = NDManager.newBaseManager();\n",
    "\n",
    "fun getDataCh11(batchSize: Int, n: Int) : AirfoilRandomAccess {\n",
    "    // Load data\n",
    "    val airfoil = AirfoilRandomAccess.builder()\n",
    "            .optUsage(Dataset.Usage.TRAIN)\n",
    "            .setSampling(batchSize, true)\n",
    "            .optNormalize(true)\n",
    "            .optLimit(n.toLong())\n",
    "            .build()\n",
    "    return airfoil\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation from Scratch\n",
    "\n",
    "Recall the minibatch SGD implementation from :numref:`sec_linear_scratch`. In the following we provide a slightly more general implementation. For convenience it has the same call signature as the other optimization algorithms introduced later in this chapter. Specifically, we add the status\n",
    "input `states` and place the hyperparameter in dictionary `hyperparams`. In\n",
    "addition, we will average the loss of each minibatch example in the training\n",
    "function, so the gradient in the optimization algorithm does not need to be\n",
    "divided by the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "object Optimization {\n",
    "    fun sgd(params: NDList, states: NDList, hyperparams: Map<String, Float>) {\n",
    "        val lrt = Tracker.fixed(hyperparams.get(\"lr\")!!)\n",
    "        val opt = Optimizer.sgd().setLearningRateTracker(lrt).build()\n",
    "        for (param in params) {\n",
    "            // Update param in place.\n",
    "            // param = param - param.gradient * lr / batchSize\n",
    "            // val ind = params.indexOf(param)\n",
    "            // params.rep\n",
    "            // params.set(ind, param.sub(param.getGradient().mul(lr).div(batchSize)))\n",
    "            opt.update(param.toString(), param, param.gradient)\n",
    "//            param.subi(param.getGradient().mul(lr).div(batchSize));\n",
    "        }\n",
    "\n",
    "//        for (i in 0 until params.size) {\n",
    "//            val param = params.get(i);\n",
    "            // Update param\n",
    "            // param = param - param.gradient * lr\n",
    "//            param.subi(param.getGradient().mul(hyperparams.get(\"lr\")));\n",
    "//        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we implement a generic training function to facilitate the use of the other optimization algorithms introduced later in this chapter. It initializes a linear regression model and can be used to train the model with minibatch SGD and other algorithms introduced subsequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun evaluateLoss( dataIterator: Iterable<Batch>, w: NDArray, b: NDArray): Float {\n",
    "    val metric = Accumulator(2);  // sumLoss, numExamples\n",
    "\n",
    "    for (batch in dataIterator) {\n",
    "        val X = batch.getData().head();\n",
    "        val y = batch.getLabels().head();\n",
    "        val yHat = Training.linreg(X, w, b);\n",
    "        val lossSum = Training.squaredLoss(yHat, y).sum().getFloat();\n",
    "\n",
    "        metric.add(floatArrayOf(lossSum, y.size().toFloat()))\n",
    "        batch.close()\n",
    "    }\n",
    "    return metric.get(0) / metric.get(1);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossTime(val epoch: List<Double>, val loss: List<Float>, val time: List<Double>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun plotLossEpoch(loss: List<Float>, epoch: List<Double>) : Plot {\n",
    "    val dd = mapOf( \"x\" to epoch, \"y\" to loss)\n",
    "var plot = letsPlot()\n",
    "plot += geomLine(data=dd) { x = \"x\" ; y = \"y\" }\n",
    "return plot + ggsize(500, 400)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun trainCh11(trainer: (NDList, NDList, Map<String, Float>)-> Unit,\n",
    "              states: NDList,\n",
    "              hyperparams: Map<String, Float> ,\n",
    "              dataset: AirfoilRandomAccess ,\n",
    "              featureDim: Int,\n",
    "              numEpochs: Int) : LossTime {\n",
    "    val manager = NDManager.newBaseManager();\n",
    "    val w = manager.randomNormal(0f, 0.01f, Shape(featureDim.toLong(), 1), DataType.FLOAT32);\n",
    "    val b = manager.zeros(Shape(1));\n",
    "\n",
    "    w.setRequiresGradient(true);\n",
    "    b.setRequiresGradient(true);\n",
    "\n",
    "    val params = NDList(w, b);\n",
    "    var n = 0;\n",
    "    val stopWatch = StopWatch();\n",
    "    stopWatch.start();\n",
    "\n",
    "    var lastLoss = -1.0f;\n",
    "    val loss = mutableListOf<Float>();\n",
    "    val epoch = mutableListOf<Double>()\n",
    "    \n",
    "    for (i in 0 until numEpochs) {\n",
    "        for (batch in dataset.getData(manager)) {\n",
    "            val len = (dataset.size() / batch.getSize()).toInt()  // number of batches\n",
    "            val X = batch.getData().head();\n",
    "            val y = batch.getLabels().head();\n",
    "\n",
    "            val gc = Engine.getInstance().newGradientCollector()\n",
    "                val yHat = Training.linreg(X, params.get(0), params.get(1));\n",
    "                val l = Training.squaredLoss(yHat, y).mean();\n",
    "                gc.backward(l);\n",
    "\n",
    "            trainer(params, states, hyperparams);\n",
    "            n += X.getShape().get(0).toInt()\n",
    "\n",
    "            if (n % 200 == 0) {\n",
    "                stopWatch.stop();\n",
    "                lastLoss = evaluateLoss(dataset.getData(manager), params.get(0), params.get(1));\n",
    "                loss.add(lastLoss);\n",
    "                val lastEpoch = 1.0 * n / X.getShape().get(0) / len\n",
    "                epoch.add(lastEpoch);\n",
    "                stopWatch.start()\n",
    "            }\n",
    "\n",
    "            batch.close();\n",
    "        }\n",
    "    }\n",
    "    System.out.printf(\"loss: %.3f, %.3f sec/epoch\\n\", lastLoss, stopWatch.avg());\n",
    "//    plotLossEpoch(lossArray, epochArray);\n",
    "    return LossTime(epoch, loss, stopWatch.cumsum());\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how optimization proceeds for batch gradient descent. This can be achieved by setting the minibatch size to 1500 (i.e., to the total number of examples). As a result the model parameters are updated only once per epoch. There is little progress. In fact, after 6 steps progress stalls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.246, 0.032 sec/epoch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "   <div id=\"1e9IQ1\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"plot\">\n",
       "       (function() {\n",
       "           var plotSpec={\n",
       "\"mapping\":{\n",
       "},\n",
       "\"ggsize\":{\n",
       "\"width\":500.0,\n",
       "\"height\":400.0\n",
       "},\n",
       "\"kind\":\"plot\",\n",
       "\"scales\":[],\n",
       "\"layers\":[{\n",
       "\"mapping\":{\n",
       "\"x\":\"x\",\n",
       "\"y\":\"y\"\n",
       "},\n",
       "\"stat\":\"identity\",\n",
       "\"data\":{\n",
       "\"x\":[2.0,4.0,6.0,8.0,10.0],\n",
       "\"y\":[0.2499961107969284,0.24518975615501404,0.24467559158802032,0.24507726728916168,0.24617533385753632]\n",
       "},\n",
       "\"position\":\"identity\",\n",
       "\"geom\":\"line\"\n",
       "}]\n",
       "};\n",
       "           var plotContainer = document.getElementById(\"1e9IQ1\");\n",
       "           window.letsPlotCall(function() {{\n",
       "               LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer);\n",
       "           }});\n",
       "       })();    \n",
       "   </script>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun  trainSgd(lr: Float, batchSize: Int,numEpochs: Int) : LossTime {\n",
    "    val dataset = getDataCh11(batchSize, 1500);\n",
    "    val featureDim = dataset.getColumnNames().size\n",
    "\n",
    "    val hyperparams = mutableMapOf<String, Float>()\n",
    "    hyperparams.put(\"lr\", lr);\n",
    "\n",
    "    return trainCh11(Optimization::sgd, NDList(), hyperparams, dataset, featureDim, numEpochs);\n",
    "}\n",
    "\n",
    "val gdRes = trainSgd(1f, 1500, 10)\n",
    "plotLossEpoch(gdRes.loss, gdRes.epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the batch size equals 1, we use SGD for optimization. For simplicity of implementation we picked a constant (albeit small) learning rate. In SGD, the model parameters are updated whenever an example is processed. In our case this amounts to 1500 updates per epoch. As we can see, the decline in the value of the objective function slows down after one epoch. Although both the procedures processed 1500 examples within one epoch, SGD consumes more time than gradient descent in our experiment. This is because SGD updated the parameters more frequently and since it is less efficient to process single observations one at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.244, 0.089 sec/epoch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "   <div id=\"kO3ICy\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"plot\">\n",
       "       (function() {\n",
       "           var plotSpec={\n",
       "\"mapping\":{\n",
       "},\n",
       "\"ggsize\":{\n",
       "\"width\":500.0,\n",
       "\"height\":400.0\n",
       "},\n",
       "\"kind\":\"plot\",\n",
       "\"scales\":[],\n",
       "\"layers\":[{\n",
       "\"mapping\":{\n",
       "\"x\":\"x\",\n",
       "\"y\":\"y\"\n",
       "},\n",
       "\"stat\":\"identity\",\n",
       "\"data\":{\n",
       "\"x\":[0.13333333333333333,0.26666666666666666,0.4,0.5333333333333333,0.6666666666666666,0.8,0.9333333333333333,1.0666666666666667,1.2,1.3333333333333333,1.4666666666666666,1.6,1.7333333333333334,1.8666666666666667,2.0],\n",
       "\"y\":[0.3314255177974701,0.27092406153678894,0.2506083846092224,0.24999463558197021,0.24780547618865967,0.24441710114479065,0.24820493161678314,0.246289923787117,0.24366118013858795,0.24392487108707428,0.24712532758712769,0.24491742253303528,0.24440276622772217,0.24251173436641693,0.24393446743488312]\n",
       "},\n",
       "\"position\":\"identity\",\n",
       "\"geom\":\"line\"\n",
       "}]\n",
       "};\n",
       "           var plotContainer = document.getElementById(\"kO3ICy\");\n",
       "           window.letsPlotCall(function() {{\n",
       "               LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer);\n",
       "           }});\n",
       "       })();    \n",
       "   </script>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sgdRes = trainSgd(0.005f, 1, 2);\n",
    "plotLossEpoch(sgdRes.loss, sgdRes.epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, when the batch size equals 100, we use minibatch SGD for optimization. The time required per epoch is longer than the time needed for SGD and the time for batch gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.244, 0.005 sec/epoch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "   <div id=\"HggcZ5\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"plot\">\n",
       "       (function() {\n",
       "           var plotSpec={\n",
       "\"mapping\":{\n",
       "},\n",
       "\"ggsize\":{\n",
       "\"width\":500.0,\n",
       "\"height\":400.0\n",
       "},\n",
       "\"kind\":\"plot\",\n",
       "\"scales\":[],\n",
       "\"layers\":[{\n",
       "\"mapping\":{\n",
       "\"x\":\"x\",\n",
       "\"y\":\"y\"\n",
       "},\n",
       "\"stat\":\"identity\",\n",
       "\"data\":{\n",
       "\"x\":[0.13333333333333333,0.26666666666666666,0.4,0.5333333333333333,0.6666666666666666,0.8,0.9333333333333333,1.0666666666666667,1.2,1.3333333333333333,1.4666666666666666,1.6,1.7333333333333334,1.8666666666666667,2.0],\n",
       "\"y\":[0.3157655894756317,0.2730814516544342,0.25554680824279785,0.2566826343536377,0.2470797300338745,0.24536427855491638,0.2449527531862259,0.24644042551517487,0.2445714920759201,0.24357695877552032,0.24626193940639496,0.2433794140815735,0.24264603853225708,0.24414946138858795,0.2442316710948944]\n",
       "},\n",
       "\"position\":\"identity\",\n",
       "\"geom\":\"line\"\n",
       "}]\n",
       "};\n",
       "           var plotContainer = document.getElementById(\"HggcZ5\");\n",
       "           window.letsPlotCall(function() {{\n",
       "               LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer);\n",
       "           }});\n",
       "       })();    \n",
       "   </script>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mini1Res = trainSgd(0.4f, 100, 2);\n",
    "plotLossEpoch(mini1Res.loss, mini1Res.epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing the batch size to 10, the time for each epoch increases because the workload for each batch is less efficient to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.244, 0.010 sec/epoch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "   <div id=\"njbPtc\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"plot\">\n",
       "       (function() {\n",
       "           var plotSpec={\n",
       "\"mapping\":{\n",
       "},\n",
       "\"ggsize\":{\n",
       "\"width\":500.0,\n",
       "\"height\":400.0\n",
       "},\n",
       "\"kind\":\"plot\",\n",
       "\"scales\":[],\n",
       "\"layers\":[{\n",
       "\"mapping\":{\n",
       "\"x\":\"x\",\n",
       "\"y\":\"y\"\n",
       "},\n",
       "\"stat\":\"identity\",\n",
       "\"data\":{\n",
       "\"x\":[0.13333333333333333,0.26666666666666666,0.4,0.5333333333333333,0.6666666666666666,0.8,0.9333333333333333,1.0666666666666667,1.2,1.3333333333333333,1.4666666666666666,1.6,1.7333333333333334,1.8666666666666667,2.0],\n",
       "\"y\":[0.32633230090141296,0.2780354619026184,0.24946549534797668,0.24996820092201233,0.24410304427146912,0.24460333585739136,0.24534474313259125,0.24712832272052765,0.24788382649421692,0.2438386231660843,0.24436432123184204,0.24275067448616028,0.2454698234796524,0.24407361447811127,0.24422790110111237]\n",
       "},\n",
       "\"position\":\"identity\",\n",
       "\"geom\":\"line\"\n",
       "}]\n",
       "};\n",
       "           var plotContainer = document.getElementById(\"njbPtc\");\n",
       "           window.letsPlotCall(function() {{\n",
       "               LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer);\n",
       "           }});\n",
       "       })();    \n",
       "   </script>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mini2Res = trainSgd(0.05f, 10, 2);\n",
    "plotLossEpoch(mini2Res.loss, mini2Res.epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compare the time versus loss for the preview four experiments. As can be seen, despite SGD converges faster than GD in terms of number of examples processed, it uses more time to reach the same loss than GD because that computing gradient example by example is not efficient. Minibatch SGD is able to trade-off the convergence speed and computation efficiency. A minibatch size 10 is more efficient than SGD; a minibatch size 100 even outperforms GD in terms of runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun getTypeArray(lossTime: LossTime ,  name: String) : List<String> {\n",
    "    return List<String>(lossTime.time.size) { name }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Converts a float array to a log scale\n",
    "fun convertLogScale(array: List<Double>) : List<Double>{\n",
    "    return array.map { kotlin.math.log10(it)}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "   <div id=\"0JpxOh\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"plot\">\n",
       "       (function() {\n",
       "           var plotSpec={\n",
       "\"mapping\":{\n",
       "},\n",
       "\"ggsize\":{\n",
       "\"width\":700.0,\n",
       "\"height\":400.0\n",
       "},\n",
       "\"kind\":\"plot\",\n",
       "\"scales\":[],\n",
       "\"layers\":[{\n",
       "\"mapping\":{\n",
       "\"x\":\"x\",\n",
       "\"y\":\"y\",\n",
       "\"color\":\"z\"\n",
       "},\n",
       "\"stat\":\"identity\",\n",
       "\"data\":{\n",
       "\"x\":[-1.4583371499339581,-1.1632171419688122,-1.0119880456036472,-0.8893560904382422,-0.7913767402233962,-0.9909223668636272,-0.72581212077317,-0.5332383722904205,-0.38901072810373766,-0.31120513802490646,-0.24870410978130894,-0.19604332341368877,-0.14700123682437072,-0.10348221495978673,-0.06572269124058952,-0.026810333138099725,0.010358141416697251,0.056211026268320516,0.09643866941349334,0.1266557521172393,-1.8075886754365875,-1.7205338266920944,-1.6634402098252812,-1.612976986982429,-1.5557958878498264,-1.3401931000405192,-1.3122231960356663,-1.2905629695756353,-1.271533397245532,-1.253558085087259,-1.2361828134103103,-1.2205088487496327,-1.1978648490695332,-1.1821901194386766,-1.1671144363403043,-1.5255375112142826,-1.3561625511765043,-1.2901790382900584,-1.2347808707946095,-1.169529383081362,-1.1145590535343646,-1.0709895030903225,-1.0085851801751555,-0.9780325636805589,-0.946270986642921,-0.9133060335368332,-0.8753190936854197,-0.853031178056875,-0.8314079483961906,-0.8076511426651445],\n",
       "\"y\":[0.2499961107969284,0.24518975615501404,0.24467559158802032,0.24507726728916168,0.24617533385753632,0.3314255177974701,0.27092406153678894,0.2506083846092224,0.24999463558197021,0.24780547618865967,0.24441710114479065,0.24820493161678314,0.246289923787117,0.24366118013858795,0.24392487108707428,0.24712532758712769,0.24491742253303528,0.24440276622772217,0.24251173436641693,0.24393446743488312,0.3157655894756317,0.2730814516544342,0.25554680824279785,0.2566826343536377,0.2470797300338745,0.24536427855491638,0.2449527531862259,0.24644042551517487,0.2445714920759201,0.24357695877552032,0.24626193940639496,0.2433794140815735,0.24264603853225708,0.24414946138858795,0.2442316710948944,0.32633230090141296,0.2780354619026184,0.24946549534797668,0.24996820092201233,0.24410304427146912,0.24460333585739136,0.24534474313259125,0.24712832272052765,0.24788382649421692,0.2438386231660843,0.24436432123184204,0.24275067448616028,0.2454698234796524,0.24407361447811127,0.24422790110111237],\n",
       "\"z\":[\"gd\",\"gd\",\"gd\",\"gd\",\"gd\",\"sgd\",\"sgd\",\"sgd\",\"sgd\",\"sgd\",\"sgd\",\"sgd\",\"sgd\",\"sgd\",\"sgd\",\"sgd\",\"sgd\",\"sgd\",\"sgd\",\"sgd\",\"batch size = 100\",\"batch size = 100\",\"batch size = 100\",\"batch size = 100\",\"batch size = 100\",\"batch size = 100\",\"batch size = 100\",\"batch size = 100\",\"batch size = 100\",\"batch size = 100\",\"batch size = 100\",\"batch size = 100\",\"batch size = 100\",\"batch size = 100\",\"batch size = 100\",\"batch size = 10\",\"batch size = 10\",\"batch size = 10\",\"batch size = 10\",\"batch size = 10\",\"batch size = 10\",\"batch size = 10\",\"batch size = 10\",\"batch size = 10\",\"batch size = 10\",\"batch size = 10\",\"batch size = 10\",\"batch size = 10\",\"batch size = 10\",\"batch size = 10\"]\n",
       "},\n",
       "\"position\":\"identity\",\n",
       "\"geom\":\"line\"\n",
       "}]\n",
       "};\n",
       "           var plotContainer = document.getElementById(\"0JpxOh\");\n",
       "           window.letsPlotCall(function() {{\n",
       "               LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer);\n",
       "           }});\n",
       "       })();    \n",
       "   </script>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val time = convertLogScale(gdRes.time+ sgdRes.time + mini1Res.time+ mini2Res.time)\n",
    "val loss = gdRes.loss+ sgdRes.loss + mini1Res.loss+ mini2Res.loss\n",
    "val type = getTypeArray(gdRes, \"gd\") + getTypeArray(sgdRes, \"sgd\") +getTypeArray(mini1Res, \"batch size = 100\")+getTypeArray(mini1Res, \"batch size = 10\")\n",
    "    val dd = mapOf( \"x\" to time, \"y\" to loss, \"z\" to type)\n",
    "var plot = letsPlot()\n",
    "plot += geomLine(data=dd) { x = \"x\" ; y = \"y\" ; color = \"z\"}\n",
    "plot + ggsize(700, 400)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concise Implementation\n",
    "\n",
    "In DJL, we can use the `Optimizer` package to access different optimization algorithms. This is used to implement a generic training function. We will use this throughout the current chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ai.djl.metric.Metrics\n",
    "fun trainConciseCh11(sgd:Optimizer , dataset:AirfoilRandomAccess , \n",
    "                            numEpochs: Int) : kotlin.Pair<List<Double>, List<Float>> {\n",
    "    // Initialization\n",
    "    val manager = NDManager.newBaseManager();\n",
    "\n",
    "    val net = SequentialBlock();\n",
    "    val linear = Linear.builder().setUnits(1).build();\n",
    "    net.add(linear);\n",
    "    net.setInitializer(NormalInitializer(), Parameter.Type.WEIGHT);\n",
    "\n",
    "    val model = Model.newInstance(\"concise implementation\");\n",
    "    model.setBlock(net);\n",
    "\n",
    "    val loss = Loss.l2Loss();\n",
    "\n",
    "    val config = DefaultTrainingConfig(loss)\n",
    "        .optOptimizer(sgd)\n",
    "        .addEvaluator(Accuracy()) // Model Accuracy\n",
    "        .addTrainingListeners(*TrainingListener.Defaults.logging()) // Logging\n",
    "\n",
    "    val trainer = model.newTrainer(config);\n",
    "\n",
    "    var n = 0L;\n",
    "    val stopWatch = StopWatch();\n",
    "    stopWatch.start();\n",
    "\n",
    "    trainer.initialize(Shape(10, 5));\n",
    "\n",
    "    val metrics = Metrics();\n",
    "    trainer.setMetrics(metrics);\n",
    "\n",
    "    var lastLoss = -1.0f;\n",
    "    \n",
    "    val lossArray = mutableListOf<Float>()\n",
    "    val epochArray = mutableListOf<Double>()\n",
    "    for (epoch in 0 until numEpochs) {\n",
    "    for (batch in trainer.iterateDataset(dataset)) {\n",
    "        val len = dataset.size() / batch.getSize()  // number of batches\n",
    "\n",
    "        val X = batch.getData().head();\n",
    "        EasyTrain.trainBatch(trainer, batch);\n",
    "        trainer.step();\n",
    "        \n",
    "        n += X.getShape().get(0);\n",
    "        \n",
    "        if (n % 200 == 0L) {\n",
    "            stopWatch.stop();\n",
    "            stopWatch.stop();\n",
    "            lastLoss = evaluateLoss(dataset.getData(manager), linear.getParameters().get(0).getValue().getArray()\n",
    "                            .reshape(Shape(dataset.getColumnNames().size.toLong(), 1L)),\n",
    "                    linear.getParameters().get(1).getValue().getArray());\n",
    "            lossArray.add(lastLoss);\n",
    "            val lastEpoch = 1.0 * n / X.getShape().get(0) / len;\n",
    "            epochArray.add(lastEpoch);\n",
    "            stopWatch.start();\n",
    "        }\n",
    "        batch.close();\n",
    "    }\n",
    "    }\n",
    "//    plotLossEpoch(arrayListToFloat(lossArray), arrayListToFloat(epochArray));\n",
    "\n",
    "    System.out.printf(\"loss: %.3f, %.3f sec/epoch\\n\", lastLoss, stopWatch.avg());\n",
    "    return kotlin.Pair(epochArray, lossArray)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using DJL to repeat the last experiment shows identical behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:    100% |████████████████████████████████████████| Accuracy: 0.68, L2Loss: 0.27�███                                  | Accuracy: 0.69, L2Loss: 0.34racy: 0.69, L2Loss: 0.34              | Accuracy: 0.67, L2Loss: 0.32curacy: 0.67, L2Loss: 0.32��███                   | Accuracy: 0.67, L2Loss: 0.31��█████████████████               | Accuracy: 0.68, L2Loss: 0.30�███████████████████            | Accuracy: 0.68, L2Loss: 0.30     75% |███████████████████████████████         | Accuracy: 0.67, L2Loss: 0.30�████████████████████████     | Accuracy: 0.67, L2Loss: 0.28�███████████████████  | Accuracy: 0.67, L2Loss: 0.28Loss: 0.28\n",
      "Training:    100% |████████████████████████████████████████| Accuracy: 0.67, L2Loss: 0.26�███                                  | Accuracy: 0.67, L2Loss: 0.27��██                              | Accuracy: 0.68, L2Loss: 0.27              | Accuracy: 0.68, L2Loss: 0.27curacy: 0.68, L2Loss: 0.27                | Accuracy: 0.68, L2Loss: 0.270.27ining:     68% |████████████████████████████            | Accuracy: 0.68, L2Loss: 0.26█████████████████████     | Accuracy: 0.68, L2Loss: 0.26�████████████   | Accuracy: 0.68, L2Loss: 0.26: 0.26\n",
      "loss: 0.244, 0.038 sec/epoch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "   <div id=\"9S9ryV\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"plot\">\n",
       "       (function() {\n",
       "           var plotSpec={\n",
       "\"mapping\":{\n",
       "},\n",
       "\"ggsize\":{\n",
       "\"width\":500.0,\n",
       "\"height\":400.0\n",
       "},\n",
       "\"kind\":\"plot\",\n",
       "\"scales\":[],\n",
       "\"layers\":[{\n",
       "\"mapping\":{\n",
       "\"x\":\"x\",\n",
       "\"y\":\"y\"\n",
       "},\n",
       "\"stat\":\"identity\",\n",
       "\"data\":{\n",
       "\"x\":[0.13333333333333333,0.26666666666666666,0.4,0.5333333333333333,0.6666666666666666,0.8,0.9333333333333333,1.0666666666666667,1.2,1.3333333333333333,1.4666666666666666,1.6,1.7333333333333334,1.8666666666666667,2.0],\n",
       "\"y\":[0.32307273149490356,0.26786231994628906,0.2551684081554413,0.24912934005260468,0.24528926610946655,0.2432592809200287,0.24556505680084229,0.24494650959968567,0.2439083307981491,0.24311813712120056,0.2439168244600296,0.24426031112670898,0.24447457492351532,0.2430570125579834,0.24371425807476044]\n",
       "},\n",
       "\"position\":\"identity\",\n",
       "\"geom\":\"line\"\n",
       "}]\n",
       "};\n",
       "           var plotContainer = document.getElementById(\"9S9ryV\");\n",
       "           window.letsPlotCall(function() {{\n",
       "               LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer);\n",
       "           }});\n",
       "       })();    \n",
       "   </script>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val airfoilDataset = getDataCh11(10, 1500);\n",
    "\n",
    "val lrt = Tracker.fixed(0.05f);\n",
    "val sgd = Optimizer.sgd().setLearningRateTracker(lrt).build();\n",
    "\n",
    "val res = trainConciseCh11(sgd, airfoilDataset, 2)\n",
    "plotLossEpoch(res.second, res.first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* Vectorization makes code more efficient due to reduced overhead arising from the deep learning framework and due to better memory locality and caching on CPUs and GPUs. \n",
    "* There is a trade-off between statistical efficiency arising from SGD and computational efficiency arising from processing large batches of data at a time. \n",
    "* Minibatch stochastic gradient descent offers the best of both worlds: computational and statistical efficiency. \n",
    "* In minibatch SGD we process batches of data obtained by a random permutation of the training data (i.e., each observation is processed only once per epoch, albeit in random order). \n",
    "* It is advisable to decay the learning rates during training. \n",
    "* In general, minibatch SGD is faster than SGD and gradient descent for convergence to a smaller risk, when measured in terms of clock time.  \n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Modify the batch size and learning rate and observe the rate of decline for the value of the objective function and the time consumed in each epoch.\n",
    "1. Read the DJL documentation and explore the different learning rate trackers in `ai.djl.training.optimizer.tracker` to see how they affect training. Try using a `FactorTracker` to reduce the learning rate to 1/10 of its previous value after each epoch.\n",
    "1. Compare minibatch SGD with a variant that actually *samples with replacement* from the training set. What happens?\n",
    "1. An evil genie replicates your dataset without telling you (i.e., each observation occurs twice and your dataset grows to twice its original size, but nobody told you). How does the behavior of SGD, minibatch SGD and that of gradient descent change?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "codemirror_mode": "text/x-kotlin",
   "file_extension": ".kt",
   "mimetype": "text/x-kotlin",
   "name": "kotlin",
   "nbconvert_exporter": "",
   "pygments_lexer": "kotlin",
   "version": "1.8.0-dev-707"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
