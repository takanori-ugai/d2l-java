{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d1340b4",
   "metadata": {},
   "source": [
    "# Bahdanau Attention\n",
    "\n",
    ":label:`sec_seq2seq_attention`\n",
    "\n",
    "When we encountered machine translation in :numref:`sec_seq2seq`,\n",
    "we designed an encoder-decoder architecture \n",
    "based on two RNNs for sequence-to-sequence learning.\n",
    "Specifically, the RNN encoder transforms a variable-length sequence\n",
    "into a fixed-shape context variable.\n",
    "Then, the RNN decoder generates the output (target) sequence token by token\n",
    "based on the generated tokens and the context variable.\n",
    "However, while not all input (source) tokens\n",
    "are relevant when decoding a particular target token,\n",
    "the *same* context variable\n",
    "that encodes the entire input sequence\n",
    "is still used at each decoding step.\n",
    "\n",
    "In a separate but related challenge \n",
    "of handwriting generation for a given text sequence,\n",
    ":citet:`Graves.2013` designed a differentiable attention model\n",
    "to align text characters with the much longer pen trace,\n",
    "where the alignment moves only in one direction.\n",
    "Inspired by the idea of learning to align,\n",
    ":citet:`Bahdanau.Cho.Bengio.2014` proposed a differentiable attention model\n",
    "without the severe unidirectional alignment limitation.\n",
    "When predicting a token,\n",
    "if not all the input tokens are relevant,\n",
    "the model aligns (or attends)\n",
    "only to parts of the input sequence \n",
    "that are deemed relevant to the current prediction.\n",
    "This is achieved by constructing the context variable\n",
    "via an attention mechanism. \n",
    "\n",
    "## Model\n",
    "\n",
    "To describe the  Bahdanau-style attention mechanism \n",
    "for the RNN encoder-decoder below,\n",
    "we follow the same notation as in :numref:`sec_seq2seq`.\n",
    "The new attention-based model follows \n",
    "the sequence-to-sequence architecture of :numref:`sec_seq2seq`,\n",
    "but with the context variable $\\mathbf{c}$ in :eqref:`eq_seq2seq_s_t`\n",
    "replaced by $\\mathbf{c}_{t'}$\n",
    "at any decoding time step $t'$.\n",
    "Suppose that there are $T$ tokens in the input sequence,\n",
    "the context variable at the decoding time step $t'$\n",
    "is the output of attention pooling:\n",
    "\n",
    "$$\\mathbf{c}_{t'} = \\sum_{t=1}^T \\alpha(\\mathbf{s}_{t' - 1}, \\mathbf{h}_t) \\mathbf{h}_t,$$\n",
    "\n",
    "where the decoder hidden state\n",
    "$\\mathbf{s}_{t' - 1}$ at time step $t' - 1$ is the query,\n",
    "and the encoder hidden states $\\mathbf{h}_t$\n",
    "are both the keys and values,\n",
    "and the attention weight $\\alpha$\n",
    "is computed as in\n",
    ":eqref:`eq_attn-scoring-alpha`\n",
    "using the additive attention scoring function\n",
    "defined by :eqref:`eq_additive-attn`.\n",
    "\n",
    "This RNN encoder-decoder architecture\n",
    "augmented  Bahdanau attention \n",
    "is depicted in :numref:`fig_s2s_attention_details`.\n",
    "\n",
    "![Layers in an RNN encoder-decoder model with Bahdanau attention.](https://github.com/d2l-ai/d2l-en/raw/master/img/seq2seq-attention-details.svg)\n",
    ":label:`fig_s2s_attention_details`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "492dce54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "   <div id=\"7lXMrM\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "       if(!window.letsPlotCallQueue) {\n",
       "           window.letsPlotCallQueue = [];\n",
       "       }; \n",
       "       window.letsPlotCall = function(f) {\n",
       "           window.letsPlotCallQueue.push(f);\n",
       "       };\n",
       "       (function() {\n",
       "           var script = document.createElement(\"script\");\n",
       "           script.type = \"text/javascript\";\n",
       "           script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v2.4.0/js-package/distr/lets-plot.min.js\";\n",
       "           script.onload = function() {\n",
       "               window.letsPlotCall = function(f) {f();};\n",
       "               window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "               window.letsPlotCallQueue = [];\n",
       "               \n",
       "               \n",
       "           };\n",
       "           script.onerror = function(event) {\n",
       "               window.letsPlotCall = function(f) {};\n",
       "               window.letsPlotCallQueue = [];\n",
       "               var div = document.createElement(\"div\");\n",
       "               div.style.color = 'darkred';\n",
       "               div.textContent = 'Error loading Lets-Plot JS';\n",
       "               document.getElementById(\"7lXMrM\").appendChild(div);\n",
       "           };\n",
       "           var e = document.getElementById(\"7lXMrM\");\n",
       "           e.appendChild(script);\n",
       "       })();\n",
       "   </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%use @file[../djl.json]\n",
    "%use lets-plot\n",
    "@file:DependsOn(\"../D2J-1.0-SNAPSHOT.jar\")\n",
    "import jp.live.ugai.d2j.timemachine.Vocab\n",
    "import jp.live.ugai.d2j.RNNModel\n",
    "import jp.live.ugai.d2j.util.StopWatch\n",
    "import jp.live.ugai.d2j.util.Accumulator\n",
    "import jp.live.ugai.d2j.util.Training\n",
    "import jp.live.ugai.d2j.util.TrainingChapter9\n",
    "import jp.live.ugai.d2j.lstm.Decoder\n",
    "import jp.live.ugai.d2j.lstm.Encoder\n",
    "import jp.live.ugai.d2j.lstm.EncoderDecoder\n",
    "import jp.live.ugai.d2j.util.NMT\n",
    "import jp.live.ugai.d2j.attention.AdditiveAttention\n",
    "import jp.live.ugai.d2j.Seq2SeqEncoder\n",
    "import jp.live.ugai.d2j.MaskedSoftmaxCELoss\n",
    "import java.util.Locale\n",
    "import kotlin.random.Random\n",
    "import kotlin.collections.List\n",
    "import kotlin.collections.Map\n",
    "import kotlin.Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "701160b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ai.djl.modality.nlp.DefaultVocabulary\n",
    "import ai.djl.modality.nlp.Vocabulary\n",
    "import ai.djl.modality.nlp.embedding.TrainableWordEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "957c6cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "System.setProperty(\"org.slf4j.simpleLogger.showThreadName\", \"false\")\n",
    "System.setProperty(\"org.slf4j.simpleLogger.showLogName\", \"true\")\n",
    "System.setProperty(\"org.slf4j.simpleLogger.log.ai.djl.pytorch\", \"WARN\")\n",
    "System.setProperty(\"org.slf4j.simpleLogger.log.ai.djl.mxnet\", \"ERROR\")\n",
    "System.setProperty(\"org.slf4j.simpleLogger.log.ai.djl.ndarray.index\", \"ERROR\")\n",
    "System.setProperty(\"org.slf4j.simpleLogger.log.ai.djl.tensorflow\", \"WARN\")\n",
    "\n",
    "val manager = NDManager.newBaseManager()\n",
    "val ps = ParameterStore(manager, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d27408a",
   "metadata": {},
   "source": [
    "## Defining the Decoder with Attention\n",
    "\n",
    "To implement the RNN encoder-decoder \n",
    "with Bahdanau attention,\n",
    "we only need to redefine the decoder.\n",
    "To visualize the learned attention weights more conveniently,\n",
    "the following `AttentionDecoder` class\n",
    "defines [**the base interface for\n",
    "decoders with attention mechanisms**].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45755339",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract class AttentionDecoder : Decoder() {\n",
    "    var attentionWeightArr: MutableList<Pair<FloatArray,Shape>> = mutableListOf()\n",
    "    abstract override fun initState(encOutputs: NDList): NDList\n",
    "    override fun getOutputShapes(inputShapes: Array<Shape>): Array<Shape> {\n",
    "        throw UnsupportedOperationException(\"Not implemented\")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e5791b",
   "metadata": {},
   "source": [
    "Now let's [**implement\n",
    "the RNN decoder with Bahdanau attention**]\n",
    "in the following `Seq2SeqAttentionDecoder` class.\n",
    "The state of the decoder is initialized with\n",
    "(i) the encoder final-layer hidden states at all the time steps \n",
    "(as keys and values of the attention);\n",
    "(ii) the encoder all-layer hidden state at the final time step \n",
    "(to initialize the hidden state of the decoder);\n",
    "and (iii) the encoder valid length \n",
    "(to exclude the padding tokens in attention pooling).\n",
    "At each decoding time step,\n",
    "the decoder final-layer hidden state at the previous time step \n",
    "is used as the query of the attention.\n",
    "As a result, both the attention output\n",
    "and the input embedding are concatenated\n",
    "as input of the RNN decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d41788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqAttentionDecoder(\n",
    "    vocabSize: Long,\n",
    "    private val embedSize: Int,\n",
    "    private val numHiddens: Int,\n",
    "    private val numLayers: Int,\n",
    "    dropout: Float = 0f\n",
    ") : AttentionDecoder() {\n",
    "    val attention = AdditiveAttention(numHiddens, dropout)\n",
    "    val embedding: TrainableWordEmbedding\n",
    "    val rnn = GRU.builder()\n",
    "        .setNumLayers(numLayers)\n",
    "        .setStateSize(numHiddens)\n",
    "        .optReturnState(true)\n",
    "        .optBatchFirst(false)\n",
    "        .optDropRate(dropout)\n",
    "        .build()\n",
    "    val linear = Linear.builder().setUnits(vocabSize).build()\n",
    "\n",
    "    init {\n",
    "        val list: List<String> = (0 until vocabSize).map { it.toString() }\n",
    "        val vocab: Vocabulary = DefaultVocabulary(list)\n",
    "        // Embedding layer\n",
    "        embedding = TrainableWordEmbedding.builder()\n",
    "            .optNumEmbeddings(vocabSize.toInt())\n",
    "            .setEmbeddingSize(embedSize)\n",
    "            .setVocabulary(vocab)\n",
    "            .build()\n",
    "        addChildBlock(\"embedding\", embedding)\n",
    "        addChildBlock(\"rnn\", rnn)\n",
    "        addChildBlock(\"attention\", attention)\n",
    "        addChildBlock(\"linear\", linear)\n",
    "    }\n",
    "\n",
    "    override fun initState(encOutputs: NDList): NDList {\n",
    "        val outputs = encOutputs[0]\n",
    "        val hiddenState = encOutputs[1]\n",
    "        val encValidLens = if (encOutputs.size >= 3) encOutputs[2] else manager.create(0)\n",
    "        return NDList(outputs.swapAxes(0, 1), hiddenState, encValidLens)\n",
    "    }\n",
    "\n",
    "    override fun initializeChildBlocks(manager: NDManager, dataType: DataType, vararg inputShapes: Shape) {\n",
    "        embedding.initialize(manager, dataType, inputShapes[0])\n",
    "        attention.initialize(manager, DataType.FLOAT32, inputShapes[1], inputShapes[1])\n",
    "        rnn.initialize(manager, DataType.FLOAT32, Shape(1, 4, (numHiddens + embedSize).toLong()))\n",
    "        linear.initialize(manager, DataType.FLOAT32, Shape(4, numHiddens.toLong()))\n",
    "    }\n",
    "\n",
    "    override fun forwardInternal(\n",
    "        ps: ParameterStore,\n",
    "        inputs: NDList,\n",
    "        training: Boolean,\n",
    "        params: PairList<String, Any>?\n",
    "    ): NDList {\n",
    "        var outputs: NDArray? = null\n",
    "        val encOutputs = inputs[1]\n",
    "        var hiddenState: NDArray = inputs[2]\n",
    "        val encValidLens = inputs[3]\n",
    "        var input = inputs[0]\n",
    "//        # Shape of enc_outputs: (batch_size, num_steps, num_hiddens).\n",
    "//        # Shape of hidden_state: (num_layers, batch_size, num_hiddens)\n",
    "//        enc_outputs, hidden_state, enc_valid_lens = state\n",
    "//        # Shape of the output X: (num_steps, batch_size, embed_size)\n",
    "//        X = self.embedding(X).permute(1, 0, 2)\n",
    "        // The output `X` shape: (`batchSize`(4), `numSteps`(7), `embedSize`(8))\n",
    "        val X = embedding.forward(ps, NDList(input), training, params)[0].swapAxes(0, 1)\n",
    "        attentionWeightArr = mutableListOf()\n",
    "        for (x in 0 until X.size(0)) {\n",
    "            val query = hiddenState[-1].expandDims(1)\n",
    "            val context = attention.forward(ps, NDList(query, encOutputs, encOutputs, encValidLens), training, params)\n",
    "            val xArray = context[0].concat(X[x].expandDims(1), -1)\n",
    "            val out = rnn.forward(ps, NDList(xArray.swapAxes(0, 1), hiddenState), training, params)\n",
    "            hiddenState = out[1]\n",
    "            outputs = if (outputs == null) out[0] else outputs.concat(out[0])\n",
    "//            println(attention.attentionWeights?.shape)\n",
    "//            println(attentionWeights)\n",
    "            if (attention.attentionWeights != null) {\n",
    "                val att = attention.attentionWeights!!\n",
    "                attentionWeightArr.add(Pair(att.toFloatArray(), att.shape))\n",
    "            }\n",
    "        }\n",
    "        val ret = linear.forward(ps, NDList(outputs), training)\n",
    "        return NDList(ret[0].swapAxes(0, 1), encOutputs, hiddenState, encValidLens)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f5030f",
   "metadata": {},
   "source": [
    "In the following, we [**test the implemented\n",
    "decoder**] with Bahdanau attention\n",
    "using a minibatch of 4 sequence inputs\n",
    "of 7 time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be397ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: NDList size: 3\n",
      "0 : (4, 7, 16) float32\n",
      "1 : (2, 4, 16) float32\n",
      "2 : () int32\n",
      "\n",
      "NDList size: 4\n",
      "0 : (4, 7, 10) float32\n",
      "1 : (4, 7, 16) float32\n",
      "2 : (2, 4, 16) float32\n",
      "3 : () int32\n",
      "\n",
      "(4, 7, 10)\n",
      "(4, 7, 16)\n",
      "(4, 16)\n"
     ]
    }
   ],
   "source": [
    "    val vocabSize = 10\n",
    "    val embedSize = 8\n",
    "    val numHiddens = 16\n",
    "    val numLayers = 2\n",
    "    val batchSize = 4\n",
    "    val numSteps = 7\n",
    "    val encoder = Seq2SeqEncoder(vocabSize, embedSize, numHiddens, numLayers, 0f)\n",
    "    encoder.initialize(manager, DataType.FLOAT32, Shape(batchSize.toLong(), batchSize.toLong()))\n",
    "    val decoder = Seq2SeqAttentionDecoder(vocabSize.toLong(), embedSize, numHiddens, numLayers)\n",
    "    decoder.initialize(\n",
    "        manager,\n",
    "        DataType.FLOAT32,\n",
    "        Shape(batchSize.toLong(), numHiddens.toLong()),\n",
    "        Shape(batchSize.toLong(), batchSize.toLong(), numHiddens.toLong()),\n",
    "        Shape(1, batchSize.toLong(), (numHiddens + embedSize).toLong()),\n",
    "        Shape(4, numHiddens.toLong())\n",
    "    )\n",
    "    val X = manager.zeros(Shape(batchSize.toLong(), numSteps.toLong()))\n",
    "    val output = encoder.forward(ps, NDList(X), false)\n",
    "    output.add(manager.create(0))\n",
    "    val state = decoder.initState(output)\n",
    "    println(\"State: $state\")\n",
    "    val ff = decoder.forward(ps, NDList(X).addAll(state), false)\n",
    "    println(ff)\n",
    "    println(ff[0].shape) // (batch_size, num_steps, vocab_size) (4, 7, 10)\n",
    "    println(ff[1].shape) // (batch_size, num_steps, num_hiddens) (4, 7, 16)\n",
    "    println(ff[2][0].shape) // (batch_size, num_hiddens) (4, 16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457a8795",
   "metadata": {},
   "source": [
    "## [**Training**]\n",
    "\n",
    "Similar to :numref:`sec_seq2seq_training`,\n",
    "here we specify hyperparameters,\n",
    "instantiate\n",
    "an encoder and a decoder with Bahdanau attention,\n",
    "and train this model for machine translation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71cbcf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fun trainSeq2Seq(\n",
    "        net: EncoderDecoder,\n",
    "        dataset: ArrayDataset,\n",
    "        lr: Float,\n",
    "        numEpochs: Int,\n",
    "        tgtVocab: Vocab,\n",
    "        device: Device\n",
    "    ) {\n",
    "        val loss: Loss = MaskedSoftmaxCELoss()\n",
    "        val lrt: Tracker = Tracker.fixed(lr)\n",
    "        val adam: Optimizer = Optimizer.adam().optLearningRateTracker(lrt).build()\n",
    "        val config: DefaultTrainingConfig = DefaultTrainingConfig(loss)\n",
    "            .optOptimizer(adam) // Optimizer (loss function)\n",
    "            .optInitializer(XavierInitializer(), \"\")\n",
    "        val model: Model = Model.newInstance(\"\")\n",
    "        model.block = net\n",
    "        val trainer: Trainer = model.newTrainer(config)\n",
    "//    val animator = Animator()\n",
    "        var watch: StopWatch\n",
    "        var metric: Accumulator\n",
    "        var lossValue = 0.0\n",
    "        var speed = 0.0\n",
    "        for (epoch in 1..numEpochs) {\n",
    "            watch = StopWatch()\n",
    "            metric = Accumulator(2) // Sum of training loss, no. of tokens\n",
    "            // Iterate over dataset\n",
    "            for (batch in dataset.getData(manager)) {\n",
    "                val X: NDArray = batch.data.get(0)\n",
    "                val lenX: NDArray = batch.data.get(1)\n",
    "                val Y: NDArray = batch.labels.get(0)\n",
    "                val lenY: NDArray = batch.labels.get(1)\n",
    "                val bos: NDArray = manager\n",
    "                    .full(Shape(Y.shape[0]), tgtVocab.getIdx(\"<bos>\"))\n",
    "                    .reshape(-1, 1)\n",
    "                val decInput: NDArray = NDArrays.concat(\n",
    "                    NDList(bos, Y.get(NDIndex(\":, :-1\"))),\n",
    "                    1\n",
    "                ) // Teacher forcing\n",
    "                Engine.getInstance().newGradientCollector().use { gc ->\n",
    "                    val yHat: NDArray = net.forward(\n",
    "                        ParameterStore(manager, false),\n",
    "                        NDList(X, decInput, lenX),\n",
    "                        true\n",
    "                    )\n",
    "                        .get(0)\n",
    "                    val l = loss.evaluate(NDList(Y, lenY), NDList(yHat))\n",
    "                    gc.backward(l)\n",
    "                    metric.add(floatArrayOf(l.sum().getFloat(), lenY.sum().getLong().toFloat()))\n",
    "                }\n",
    "                TrainingChapter9.gradClipping(net, 1, manager)\n",
    "                // Update parameters\n",
    "                trainer.step()\n",
    "            }\n",
    "            lossValue = metric.get(0).toDouble() / metric.get(1)\n",
    "            speed = metric.get(1) / watch.stop()\n",
    "            if ((epoch + 1) % 10 == 0) {\n",
    "//            animator.add(epoch + 1, lossValue.toFloat(), \"loss\")\n",
    "//            animator.show()\n",
    "                println(\"${epoch + 1} : $lossValue\")\n",
    "            }\n",
    "        }\n",
    "        println(\"loss: %.3f, %.1f tokens/sec on %s%n\".format(lossValue, speed, device.toString()))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da483663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 : 0.13338356663607462\n",
      "20 : 0.08894217234810052\n",
      "30 : 0.07230630909913359\n",
      "40 : 0.061881931969989055\n",
      "50 : 0.053327786364174415\n",
      "60 : 0.04650633600648582\n",
      "70 : 0.04107880095054389\n",
      "80 : 0.03648166288685864\n",
      "90 : 0.03246828309666777\n",
      "100 : 0.02908570801165572\n",
      "110 : 0.026272295967231157\n",
      "120 : 0.023878186859046788\n",
      "130 : 0.021688097248580313\n",
      "140 : 0.019819132787230822\n",
      "150 : 0.01831368600604385\n",
      "160 : 0.017004677368308182\n",
      "170 : 0.015935419676389246\n",
      "180 : 0.01492106299942659\n",
      "190 : 0.01420922037280014\n",
      "200 : 0.013304892415748906\n",
      "210 : 0.012707202465503246\n",
      "220 : 0.012035523001390477\n",
      "230 : 0.011537431779221164\n",
      "240 : 0.011089678497494605\n",
      "250 : 0.010782665176121375\n",
      "260 : 0.010251179214351433\n",
      "270 : 0.00999254469137781\n",
      "280 : 0.009777232728948372\n",
      "290 : 0.009408628785765016\n",
      "300 : 0.00927302462995545\n",
      "loss: 0.009, 2065.8 tokens/sec on cpu()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    val embedSize = 32\n",
    "    val numHiddens = 32\n",
    "    val numLayers = 2\n",
    "    val batchSize = 64\n",
    "    val numSteps = 10\n",
    "    val numEpochs = Integer.getInteger(\"MAX_EPOCH\", 300)\n",
    "\n",
    "    val dropout = 0.2f\n",
    "    val lr = 0.001f\n",
    "    val device = manager.device\n",
    "\n",
    "    val dataNMT = NMT.loadDataNMT(batchSize, numSteps, 600)\n",
    "    val dataset: ArrayDataset = dataNMT.first\n",
    "    val srcVocab: Vocab = dataNMT.second.first\n",
    "    val tgtVocab: Vocab = dataNMT.second.second\n",
    "\n",
    "    val encoder = Seq2SeqEncoder(srcVocab.length(), embedSize, numHiddens, numLayers, dropout)\n",
    "    val decoder = Seq2SeqAttentionDecoder(tgtVocab.length().toLong(), embedSize, numHiddens, numLayers)\n",
    "\n",
    "    val net = EncoderDecoder(encoder, decoder)\n",
    "    trainSeq2Seq(net, dataset, lr, numEpochs, tgtVocab, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972872d3",
   "metadata": {},
   "source": [
    "After the model is trained,\n",
    "we use it to [**translate a few English sentences**]\n",
    "into French and compute their BLEU scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0af9156",
   "metadata": {},
   "outputs": [],
   "source": [
    "    fun predictSeq2Seq(\n",
    "        net: EncoderDecoder,\n",
    "        srcSentence: String,\n",
    "        srcVocab: Vocab,\n",
    "        tgtVocab: Vocab,\n",
    "        numSteps: Int,\n",
    "        device: Device,\n",
    "        saveAttentionWeights: Boolean\n",
    "    ): Pair<String, List<List<Pair<FloatArray, Shape>>>> {\n",
    "        val srcTokens = srcVocab.getIdxs(srcSentence.lowercase(Locale.getDefault()).split(\" \")) + listOf(srcVocab.getIdx(\"<eos>\"))\n",
    "        val encValidLen = manager.create(srcTokens.size)\n",
    "        val truncateSrcTokens = NMT.truncatePad(srcTokens, numSteps, srcVocab.getIdx(\"<pad>\"))\n",
    "        // Add the batch axis\n",
    "        val encX = manager.create(truncateSrcTokens.toIntArray()).expandDims(0)\n",
    "        val encOutputs = net.encoder.forward(ParameterStore(manager, false), NDList(encX, encValidLen), false)\n",
    "        var decState = net.decoder.initState(encOutputs.addAll(NDList(encValidLen)))\n",
    "        // Add the batch axis\n",
    "        var decX = manager.create(floatArrayOf(tgtVocab.getIdx(\"<bos>\").toFloat())).expandDims(0)\n",
    "        val outputSeq: MutableList<Int> = mutableListOf()\n",
    "        val attentionWeightSeq: MutableList<List<Pair<FloatArray, Shape>>> = mutableListOf()\n",
    "        for (i in 0 until numSteps) {\n",
    "            val output = net.decoder.forward(\n",
    "                ParameterStore(manager, false),\n",
    "                NDList(decX).addAll(decState),\n",
    "                false\n",
    "            )\n",
    "            val Y = output[0]\n",
    "            decState = output.subNDList(1)\n",
    "            // We use the token with the highest prediction likelihood as the input\n",
    "            // of the decoder at the next time step\n",
    "            decX = Y.argMax(2)\n",
    "            val pred = decX.squeeze(0).getLong().toInt()\n",
    "            // Save attention weights (to be covered later)\n",
    "            if (saveAttentionWeights) {\n",
    "                attentionWeightSeq.add((net.decoder as AttentionDecoder).attentionWeightArr)\n",
    "            }\n",
    "            // Once the end-of-sequence token is predicted, the generation of the\n",
    "            // output sequence is complete\n",
    "            if (pred == tgtVocab.getIdx(\"<eos>\")) {\n",
    "                break\n",
    "            }\n",
    "            outputSeq.add(pred)\n",
    "        }\n",
    "        val outputString: String = tgtVocab.toTokens(outputSeq).joinToString(separator = \" \")\n",
    "        return Pair(outputString, attentionWeightSeq)\n",
    "    }\n",
    "\n",
    "    /* Compute the BLEU. */\n",
    "    fun bleu(predSeq: String, labelSeq: String, k: Int): Double {\n",
    "        val predTokens = predSeq.split(\" \")\n",
    "        val labelTokens = labelSeq.split(\" \")\n",
    "        val lenPred = predTokens.size\n",
    "        val lenLabel = labelTokens.size\n",
    "        var score = Math.exp(Math.min(0.toDouble(), 1.0 - lenLabel / lenPred))\n",
    "        for (n in 1 until k + 1) {\n",
    "            var numMatches = 0\n",
    "            val labelSubs = mutableMapOf<String, Int>()\n",
    "            for (i in 0 until lenLabel - n + 1) {\n",
    "                val key = labelTokens.subList(i, i + n).joinToString(separator = \" \")\n",
    "                labelSubs.put(key, labelSubs.getOrDefault(key, 0) + 1)\n",
    "            }\n",
    "            for (i in 0 until lenPred - n + 1) {\n",
    "                // val key =predTokens.subList(i, i + n).joinToString(\" \")\n",
    "                val key = predTokens.subList(i, i + n).joinToString(separator = \" \")\n",
    "                if (labelSubs.getOrDefault(key, 0) > 0) {\n",
    "                    numMatches += 1\n",
    "                    labelSubs.put(key, labelSubs.getOrDefault(key, 0) - 1)\n",
    "                }\n",
    "            }\n",
    "            score *= Math.pow(numMatches.toDouble() / (lenPred - n + 1).toDouble(), Math.pow(0.5, n.toDouble()))\n",
    "        }\n",
    "        return score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bc92f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . => va !, bleu 1.000\n",
      "i lost . => j'ai perdu ., bleu 1.000\n",
      "he's calm . => il est bon ., bleu 0.658\n",
      "i'm home . => je suis chez moi ., bleu 1.000\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "    val engs = arrayOf(\"go .\", \"i lost .\", \"he's calm .\", \"i'm home .\")\n",
    "    val fras = arrayOf(\"va !\", \"j'ai perdu .\", \"il est calme .\", \"je suis chez moi .\")\n",
    "    for (i in engs.indices) {\n",
    "        val pair = predictSeq2Seq(net, engs[i], srcVocab, tgtVocab, numSteps, device, false)\n",
    "        val translation: String = pair.first\n",
    "        val attentionWeightSeq = pair.second\n",
    "        println(\"%s => %s, bleu %.3f\".format(engs[i], translation, bleu(translation, fras[i], 2)))\n",
    "    }\n",
    "    println(numSteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251005fe",
   "metadata": {},
   "source": [
    "By [**visualizing the attention weights**]\n",
    "when translating the last English sentence,\n",
    "we can see that each query assigns non-uniform weights\n",
    "over key-value pairs.\n",
    "It shows that at each decoding step,\n",
    "different parts of the input sequences\n",
    "are selectively aggregated in the attention pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "994b0a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "ND: (5, 10) cpu() float32\n",
      "[[ 2.51013692e-03,  6.97515905e-04,  1.21010663e-02,  1.32435374e-02,  4.99029718e-02,  1.83202356e-01,  3.18012834e-01,  1.79773659e-01,  1.28771856e-01,  1.11784115e-01],\n",
      " [ 6.01784652e-03,  4.91461810e-03,  6.99551627e-02,  1.70189843e-01,  3.29204738e-01,  2.39405081e-01,  1.14986718e-01,  3.14249061e-02,  1.79261118e-02,  1.59750320e-02],\n",
      " [ 5.98380400e-04,  2.75306171e-04,  1.01401545e-02,  1.35161597e-02,  9.31207538e-02,  3.19551945e-01,  3.15946758e-01,  1.13761492e-01,  7.20553100e-02,  6.10337295e-02],\n",
      " [ 9.37038916e-04,  2.40883994e-04,  3.43956985e-03,  5.08535001e-03,  4.13465388e-02,  1.76077679e-01,  3.98106396e-01,  1.69010714e-01,  1.08022988e-01,  9.77328867e-02],\n",
      " [ 1.04698956e-04,  7.04538324e-05,  1.00894133e-03,  1.19440223e-03,  1.82277411e-02,  1.99527755e-01,  4.10029739e-01,  1.86897486e-01,  1.01734743e-01,  8.12040120e-02],\n",
      "]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "   <div id=\"wjO3g8\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"plot\">\n",
       "       (function() {\n",
       "           var plotSpec={\n",
       "\"mapping\":{\n",
       "},\n",
       "\"data\":{\n",
       "},\n",
       "\"ggsize\":{\n",
       "\"width\":700.0,\n",
       "\"height\":200.0\n",
       "},\n",
       "\"kind\":\"plot\",\n",
       "\"scales\":[{\n",
       "\"aesthetic\":\"fill\",\n",
       "\"scale_mapper_kind\":\"color_gradient\",\n",
       "\"high\":\"red\",\n",
       "\"low\":\"blue\"\n",
       "}],\n",
       "\"layers\":[{\n",
       "\"drop\":false,\n",
       "\"mapping\":{\n",
       "\"x\":\"x\",\n",
       "\"y\":\"y\",\n",
       "\"weight\":\"weight\"\n",
       "},\n",
       "\"stat\":\"bin2d\",\n",
       "\"position\":\"identity\",\n",
       "\"binwidth\":[1.0,1.0],\n",
       "\"geom\":\"tile\",\n",
       "\"data\":{\n",
       "\"..count..\":[0.0025101369246840477,0.006017846520990133,5.983804003335536E-4,9.370389161631465E-4,1.0469895642017946E-4,6.975159049034119E-4,0.004914618097245693,2.753061708062887E-4,2.4088399368338287E-4,7.045383244985715E-5,0.012101066298782825,0.06995516270399094,0.010140154510736465,0.0034395698457956314,0.001008941326290369,0.01324353739619255,0.17018984258174896,0.013516159728169441,0.005085350014269352,0.0011944022262468934,0.04990297183394432,0.3292047381401062,0.0931207537651062,0.04134653881192207,0.01822774112224579,0.1832023561000824,0.2394050806760788,0.319551944732666,0.1760776787996292,0.19952775537967682,0.3180128335952759,0.11498671770095825,0.3159467577934265,0.3981063961982727,0.41002973914146423,0.17977365851402283,0.031424906104803085,0.11376149207353592,0.1690107136964798,0.18689748644828796,0.1287718564271927,0.017926111817359924,0.07205531001091003,0.10802298784255981,0.10173474252223969,0.11178411543369293,0.01597503200173378,0.06103372946381569,0.09773288667201996,0.08120401203632355],\n",
       "\"x\":[0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,2.0,2.0,2.0,2.0,2.0,3.0,3.0,3.0,3.0,3.0,4.0,4.0,4.0,4.0,4.0,5.0,5.0,5.0,5.0,5.0,6.0,6.0,6.0,6.0,6.0,7.0,7.0,7.0,7.0,7.0,8.0,8.0,8.0,8.0,8.0,9.0,9.0,9.0,9.0,9.0],\n",
       "\"y\":[0.0,1.0,2.0,3.0,4.0,0.0,1.0,2.0,3.0,4.0,0.0,1.0,2.0,3.0,4.0,0.0,1.0,2.0,3.0,4.0,0.0,1.0,2.0,3.0,4.0,0.0,1.0,2.0,3.0,4.0,0.0,1.0,2.0,3.0,4.0,0.0,1.0,2.0,3.0,4.0,0.0,1.0,2.0,3.0,4.0,0.0,1.0,2.0,3.0,4.0]\n",
       "}\n",
       "}]\n",
       "};\n",
       "           var plotContainer = document.getElementById(\"wjO3g8\");\n",
       "           window.letsPlotCall(function() {{\n",
       "               LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer);\n",
       "           }});\n",
       "       })();    \n",
       "   </script>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val pair = predictSeq2Seq(net, engs.last(), srcVocab, tgtVocab, numSteps, device, true)\n",
    "    val attentions = pair.second\n",
    "println(attentions.size)\n",
    "    val matrix = manager.create(attentions[0].last().first).reshape(attentions[0].last().second)\n",
    "        .concat(manager.create(attentions[1].last().first).reshape(attentions[1].last().second))\n",
    "        .concat(manager.create(attentions[2].last().first).reshape(attentions[2].last().second))\n",
    "        .concat(manager.create(attentions[3].last().first).reshape(attentions[3].last().second))\n",
    "        .concat(manager.create(attentions[4].last().first).reshape(attentions[4].last().second)).reshape(5,10)\n",
    "    println(matrix)\n",
    "    val seriesX = mutableListOf<Long>()\n",
    "    val seriesY = mutableListOf<Long>()\n",
    "    val seriesW = mutableListOf<Float>()\n",
    "    for(i in 0 until matrix.shape[0]) {\n",
    "        val row = matrix.get(i)\n",
    "        for(j in 0 until row.shape[0]) {\n",
    "            seriesX.add(j)\n",
    "            seriesY.add(i)\n",
    "            seriesW.add(row.get(j).getFloat())\n",
    "        }\n",
    "    }\n",
    "    val data = mapOf( \"x\" to seriesX, \"y\" to seriesY)\n",
    "    var plot = letsPlot(data)\n",
    "    plot += geomBin2D(drop=false, binWidth = Pair(1,1), position = positionIdentity){x=\"x\"; y = \"y\"; weight = seriesW }\n",
    "    plot += scaleFillGradient(low=\"blue\", high=\"red\")\n",
    "//plot += scaleFillContinuous(\"red\", \"green\")\n",
    "    plot + ggsize(700, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac626890",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "When predicting a token, if not all the input tokens are relevant, the RNN encoder-decoder with Bahdanau attention selectively aggregates different parts of the input sequence. This is achieved by treating the context variable as an output of additive attention pooling.\n",
    "In the RNN encoder-decoder, Bahdanau attention treats the decoder hidden state at the previous time step as the query, and the encoder hidden states at all the time steps as both the keys and values.\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Replace GRU with LSTM in the experiment.\n",
    "1. Modify the experiment to replace the additive attention scoring function with the scaled dot-product. How does it influence the training efficiency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb262d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "codemirror_mode": "text/x-kotlin",
   "file_extension": ".kt",
   "mimetype": "text/x-kotlin",
   "name": "kotlin",
   "nbconvert_exporter": "",
   "pygments_lexer": "kotlin",
   "version": "1.8.0-dev-707"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
