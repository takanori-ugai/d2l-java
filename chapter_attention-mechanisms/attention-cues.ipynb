{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Attention Cues\n",
    ":label:`sec_attention-cues`\n",
    "\n",
    "本書にご注目いただき、ありがとうございます。注意（アテンション）を向けるとは希少な資源である。今現在、あなたはこの本を読み、それ以外を無視している。したがって、お金と同様に、あなたが注意を向けることは機会費用で支払われている。今、あなたの注意を向けるという投資が価値あるものであるように、私たちは注意を丁寧に払うという高いモチベーションで、素敵な本を作り上げた。アテンションは人生のアーチにおける要であり、あらゆる作品の例外性の鍵を握っている。\n",
    "\n",
    "経済学は希少資源の配分を研究するので、人間の注意を限られた貴重な交換可能な商品として扱う注意の経済の時代である。それを利用するために、数多くのビジネスモデルが開発されてきた。音楽や動画のストリーミングサービスでは、その広告に注意を払うか、お金を払って広告を隠すかのどちらかである。オンラインゲームの世界で成長するためには、新しいゲーマーを惹きつけるバトルに参加するために注意を払うか、瞬時に強くなるためにお金を払うか、どちらかである。タダで手に入るものはないのある。\n",
    "\n",
    "つまり、私たちを取り巻く環境には、情報が不足しているのではなく、注意が不足しているのです。視神経は1秒間に108ビットの情報を受け取っており、脳が処理できる量をはるかに超えている。幸いなことに、私たちの祖先は経験（データ）から、すべての感覚入力が同じではないことを学んできた。人類の歴史を通じて、興味のある情報の一部だけに注意を向けるという機能によって、私たちの脳は、捕食者や獲物、仲間の発見など、生存や成長、社会生活のために、より賢く資源を配分することができるようになった。\n",
    "\n",
    "\n",
    "## Attention Cues in Biology\n",
    "\n",
    "To explain how our attention is deployed in the visual world,\n",
    "a two-component framework has emerged\n",
    "and been pervasive.\n",
    "This idea dates back to William James in the 1890s,\n",
    "who is considered the \"father of American psychology\" :cite:`James.2007`.\n",
    "In this framework,\n",
    "subjects selectively direct the spotlight of attention\n",
    "using both the *nonvolitional cue* and *volitional cue*.\n",
    "\n",
    "The nonvolitional cue is based on\n",
    "the saliency and conspicuity of objects in the environment.\n",
    "Imagine there are five objects in front of you:\n",
    "a newspaper, a research paper, a cup of coffee, a notebook, and a book such as in :numref:`fig_eye-coffee`.\n",
    "While all the paper products are printed in black and white,\n",
    "the coffee cup is red.\n",
    "In other words,\n",
    "this coffee is intrinsically salient and conspicuous in\n",
    "this visual environment,\n",
    "automatically and involuntarily drawing attention.\n",
    "So you bring the fovea (the center of the macula where visual acuity is highest) onto the coffee as shown in :numref:`fig_eye-coffee`.\n",
    "\n",
    "![Using the nonvolitional cue based on saliency (red cup, non-paper), attention is involuntarily directed to the coffee.](https://raw.githubusercontent.com/d2l-ai/d2l-en/master/img/eye-coffee.png)\n",
    ":width:`400px`\n",
    ":label:`fig_eye-coffee`\n",
    "\n",
    "After drinking coffee,\n",
    "you become caffeinated and\n",
    "want to read a book.\n",
    "So you turn your head, refocus your eyes,\n",
    "and look at the book as depicted in :numref:`fig_eye-book`.\n",
    "Different from\n",
    "the case in :numref:`fig_eye-coffee`\n",
    "where the coffee biases you towards\n",
    "selecting based on saliency,\n",
    "in this task-dependent case you select the book under\n",
    "cognitive and volitional control.\n",
    "Using the volitional cue based on variable selection criteria,\n",
    "this form of attention is more deliberate.\n",
    "It is also more powerful with the subject's voluntary effort.\n",
    "\n",
    "![Using the volitional cue (want to read a book) that is task-dependent, attention is directed to the book under volitional control.](https://raw.githubusercontent.com/d2l-ai/d2l-en/master/img/eye-book.svg)\n",
    ":width:`400px`\n",
    ":label:`fig_eye-book`\n",
    "\n",
    "\n",
    "## Queries, Keys, and Values\n",
    "\n",
    "注意の展開を説明する非自発的注意と自発的注意の手がかりに触発され、以下ではこの二つの注意の手がかりを取り入れた注意機構設計の枠組みを説明する。\n",
    "\n",
    "まず始めに、非ボリショナルキューのみが利用可能なより単純な場合を考える。感覚入力に対する選択を偏らせるためには、単にパラメータ化された完全連結層や、パラメータ化されていない最大または平均プーリングを用いることができる。\n",
    "\n",
    "したがって、注意機構をそれらの完全連結層やプーリング層と区別するのは、自発的な手がかりを含むことである。注意機構の文脈では、自発的な手がかりをクエリーと呼ぶ。このようなクエリが与えられると、注意機構は注意プーリングによって感覚入力（例えば中間的な特徴表現）に対して偏った選択を行う。これらの感覚入力は注意機構の文脈では値と呼ばれる。より一般的には、全ての値はキーと対になっており、これはその感覚入力の非揮発的な手がかりと考えることができる。numref:fig_qkvに示すように、与えられたクエリー（自発的手がかり）がキー（非自発的手がかり）と相互作用できるように注意プーリングを設計することができ、これにより値（感覚入力）に対するバイアス選択が導かれる。\n",
    "\n",
    "![Attention mechanisms bias selection over values (sensory inputs) via attention pooling, which incorporates queries (volitional cues) and keys (nonvolitional cues).](https://raw.githubusercontent.com/d2l-ai/d2l-en/master/img/qkv.svg)\n",
    ":label:`fig_qkv`\n",
    "\n",
    "Note that there are many alternatives for the design of attention mechanisms.\n",
    "For instance,\n",
    "we can design a non-differentiable attention model\n",
    "that can be trained using reinforcement learning methods :cite:`Mnih.Heess.Graves.ea.2014`.\n",
    "Given the dominance of the framework in :numref:`fig_qkv`,\n",
    "models under this framework\n",
    "will be the center of our attention in this chapter.\n",
    "\n",
    "\n",
    "## Visualization of Attention\n",
    "\n",
    "Average pooling\n",
    "can be treated as a weighted average of inputs,\n",
    "where weights are uniform.\n",
    "In practice,\n",
    "attention pooling aggregates values using weighted average, where weights are computed between the given query and different keys.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "   <div id=\"z1laVE\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "       if(!window.letsPlotCallQueue) {\n",
       "           window.letsPlotCallQueue = [];\n",
       "       }; \n",
       "       window.letsPlotCall = function(f) {\n",
       "           window.letsPlotCallQueue.push(f);\n",
       "       };\n",
       "       (function() {\n",
       "           var script = document.createElement(\"script\");\n",
       "           script.type = \"text/javascript\";\n",
       "           script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v2.4.0/js-package/distr/lets-plot.min.js\";\n",
       "           script.onload = function() {\n",
       "               window.letsPlotCall = function(f) {f();};\n",
       "               window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "               window.letsPlotCallQueue = [];\n",
       "               \n",
       "               \n",
       "           };\n",
       "           script.onerror = function(event) {\n",
       "               window.letsPlotCall = function(f) {};\n",
       "               window.letsPlotCallQueue = [];\n",
       "               var div = document.createElement(\"div\");\n",
       "               div.style.color = 'darkred';\n",
       "               div.textContent = 'Error loading Lets-Plot JS';\n",
       "               document.getElementById(\"z1laVE\").appendChild(div);\n",
       "           };\n",
       "           var e = document.getElementById(\"z1laVE\");\n",
       "           e.appendChild(script);\n",
       "       })();\n",
       "   </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%use @file[../djl.json]\n",
    "%use lets-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val manager = NDManager.newBaseManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "To visualize attention weights,\n",
    "we define the `showHeatmaps` function.\n",
    "Its input `matrices` has the shape (number of rows for display, number of columns for display, number of queries, number of keys).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "For demonstration,\n",
    "we consider a simple case where\n",
    "the attention weight is one only when the query and the key are the same; otherwise it is zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "   <div id=\"RYE79x\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"plot\">\n",
       "       (function() {\n",
       "           var plotSpec={\n",
       "\"mapping\":{\n",
       "},\n",
       "\"data\":{\n",
       "},\n",
       "\"ggsize\":{\n",
       "\"width\":500.0,\n",
       "\"height\":500.0\n",
       "},\n",
       "\"kind\":\"plot\",\n",
       "\"scales\":[],\n",
       "\"layers\":[{\n",
       "\"drop\":false,\n",
       "\"mapping\":{\n",
       "\"x\":\"x\",\n",
       "\"y\":\"y\",\n",
       "\"weight\":\"weight\"\n",
       "},\n",
       "\"stat\":\"bin2d\",\n",
       "\"bins\":[10.0,10.0],\n",
       "\"position\":\"identity\",\n",
       "\"geom\":\"tile\",\n",
       "\"data\":{\n",
       "\"..count..\":[1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0],\n",
       "\"x\":[1.045,1.045,1.045,1.045,1.045,1.045,1.045,1.045,1.045,1.045,2.0349999999999997,2.0349999999999997,2.0349999999999997,2.0349999999999997,2.0349999999999997,2.0349999999999997,2.0349999999999997,2.0349999999999997,2.0349999999999997,2.0349999999999997,3.0249999999999995,3.0249999999999995,3.0249999999999995,3.0249999999999995,3.0249999999999995,3.0249999999999995,3.0249999999999995,3.0249999999999995,3.0249999999999995,3.0249999999999995,4.015,4.015,4.015,4.015,4.015,4.015,4.015,4.015,4.015,4.015,5.004999999999999,5.004999999999999,5.004999999999999,5.004999999999999,5.004999999999999,5.004999999999999,5.004999999999999,5.004999999999999,5.004999999999999,5.004999999999999,5.994999999999999,5.994999999999999,5.994999999999999,5.994999999999999,5.994999999999999,5.994999999999999,5.994999999999999,5.994999999999999,5.994999999999999,5.994999999999999,6.984999999999999,6.984999999999999,6.984999999999999,6.984999999999999,6.984999999999999,6.984999999999999,6.984999999999999,6.984999999999999,6.984999999999999,6.984999999999999,7.974999999999999,7.974999999999999,7.974999999999999,7.974999999999999,7.974999999999999,7.974999999999999,7.974999999999999,7.974999999999999,7.974999999999999,7.974999999999999,8.965,8.965,8.965,8.965,8.965,8.965,8.965,8.965,8.965,8.965,9.954999999999998,9.954999999999998,9.954999999999998,9.954999999999998,9.954999999999998,9.954999999999998,9.954999999999998,9.954999999999998,9.954999999999998,9.954999999999998],\n",
       "\"y\":[1.045,2.0349999999999997,3.0249999999999995,4.015,5.004999999999999,5.994999999999999,6.984999999999999,7.974999999999999,8.965,9.954999999999998,1.045,2.0349999999999997,3.0249999999999995,4.015,5.004999999999999,5.994999999999999,6.984999999999999,7.974999999999999,8.965,9.954999999999998,1.045,2.0349999999999997,3.0249999999999995,4.015,5.004999999999999,5.994999999999999,6.984999999999999,7.974999999999999,8.965,9.954999999999998,1.045,2.0349999999999997,3.0249999999999995,4.015,5.004999999999999,5.994999999999999,6.984999999999999,7.974999999999999,8.965,9.954999999999998,1.045,2.0349999999999997,3.0249999999999995,4.015,5.004999999999999,5.994999999999999,6.984999999999999,7.974999999999999,8.965,9.954999999999998,1.045,2.0349999999999997,3.0249999999999995,4.015,5.004999999999999,5.994999999999999,6.984999999999999,7.974999999999999,8.965,9.954999999999998,1.045,2.0349999999999997,3.0249999999999995,4.015,5.004999999999999,5.994999999999999,6.984999999999999,7.974999999999999,8.965,9.954999999999998,1.045,2.0349999999999997,3.0249999999999995,4.015,5.004999999999999,5.994999999999999,6.984999999999999,7.974999999999999,8.965,9.954999999999998,1.045,2.0349999999999997,3.0249999999999995,4.015,5.004999999999999,5.994999999999999,6.984999999999999,7.974999999999999,8.965,9.954999999999998,1.045,2.0349999999999997,3.0249999999999995,4.015,5.004999999999999,5.994999999999999,6.984999999999999,7.974999999999999,8.965,9.954999999999998]\n",
       "}\n",
       "}]\n",
       "};\n",
       "           var plotContainer = document.getElementById(\"RYE79x\");\n",
       "           window.letsPlotCall(function() {{\n",
       "               LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer);\n",
       "           }});\n",
       "       })();    \n",
       "   </script>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val attentionWeights = manager.eye(10).reshape(Shape(1, 1, 10, 10))\n",
    "val matrix = attentionWeights.get(0,0)\n",
    "val seriesX = mutableListOf<Long>()\n",
    "val seriesY = mutableListOf<Long>()\n",
    "val seriesW = mutableListOf<Float>()\n",
    "for(i in 0 until matrix.shape[0]) {\n",
    "    val row = matrix.get(i)\n",
    "    for(j in 0 until row.shape[0]) {\n",
    "        seriesX.add(j+1)\n",
    "        seriesY.add(i+1)\n",
    "        seriesW.add(row.get(j).getFloat())\n",
    "    }\n",
    "}\n",
    "val data = mapOf( \"x\" to seriesX, \"y\" to seriesY)\n",
    "var plot = letsPlot(data)\n",
    "plot += geomBin2D(drop=false, bins = kotlin.Pair(10,10), position = positionIdentity){x=\"x\"; y = \"y\"; weight = seriesW}\n",
    "plot + ggsize(500, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "In the subsequent sections,\n",
    "we will often invoke this function to visualize attention weights.\n",
    "\n",
    "## Summary\n",
    "\n",
    "* Human attention is a limited, valuable, and scarce resource.\n",
    "* Subjects selectively direct attention using both the nonvolitional and volitional cues. The former is based on saliency and the latter is task-dependent.\n",
    "* Attention mechanisms are different from fully-connected layers or pooling layers due to inclusion of the volitional cues.\n",
    "* Attention mechanisms bias selection over values (sensory inputs) via attention pooling, which incorporates queries (volitional cues) and keys (nonvolitional cues). Keys and values are paired.\n",
    "* We can visualize attention weights between queries and keys.\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. What can be the volitional cue when decoding a sequence token by token in machine translation? What are the nonvolitional cues and the sensory inputs?\n",
    "1. Randomly generate a $10 \\times 10$ matrix and use the softmax operation to ensure each row is a valid probability distribution. Visualize the output attention weights.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "codemirror_mode": "text/x-kotlin",
   "file_extension": ".kt",
   "mimetype": "text/x-kotlin",
   "name": "kotlin",
   "nbconvert_exporter": "",
   "pygments_lexer": "kotlin",
   "version": "1.8.0-dev-707"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
